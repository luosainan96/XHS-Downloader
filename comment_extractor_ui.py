#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°çº¢ä¹¦è¯„è®ºæå–å™¨ - Web UIç•Œé¢
ä½¿ç”¨Streamlitåˆ›å»ºç”¨æˆ·å‹å¥½çš„ç•Œé¢
"""

import asyncio
import streamlit as st
import time
from pathlib import Path
import json
from datetime import datetime
import threading
from concurrent.futures import ThreadPoolExecutor
import queue

from dynamic_comment_extractor import DynamicCommentExtractor

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="å°çº¢ä¹¦è¯„è®ºæå–å™¨",
    page_icon="ğŸ–¼ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

def init_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    if 'extraction_status' not in st.session_state:
        st.session_state.extraction_status = 'idle'  # idle, running, completed, error
    if 'extraction_progress' not in st.session_state:
        st.session_state.extraction_progress = 0
    if 'current_task' not in st.session_state:
        st.session_state.current_task = ""
    if 'extraction_logs' not in st.session_state:
        st.session_state.extraction_logs = []
    if 'extractor' not in st.session_state:
        st.session_state.extractor = None
    if 'results' not in st.session_state:
        st.session_state.results = None
    if 'progress_queue' not in st.session_state:
        st.session_state.progress_queue = queue.Queue()

def add_log(message: str, level: str = "info"):
    """æ·»åŠ æ—¥å¿—æ¶ˆæ¯"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    st.session_state.extraction_logs.append({
        'time': timestamp,
        'level': level,
        'message': message
    })

def validate_xhs_url(url: str) -> bool:
    """éªŒè¯å°çº¢ä¹¦URLæ ¼å¼"""
    if not url:
        return False
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«å°çº¢ä¹¦åŸŸå
    if 'xiaohongshu.com' not in url:
        return False
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«exploreè·¯å¾„
    if '/explore/' not in url:
        return False
    
    return True

def extract_note_id_simple(url: str) -> str:
    """ç®€å•æå–ç¬”è®°IDç”¨äºæ˜¾ç¤º"""
    try:
        if '/explore/' in url:
            parts = url.split('/explore/')
            if len(parts) > 1:
                note_part = parts[1].split('?')[0]
                return note_part
    except:
        pass
    return "æœªçŸ¥ID"

def update_progress(progress: float, task: str):
    """æ›´æ–°è¿›åº¦å’Œä»»åŠ¡ä¿¡æ¯"""
    try:
        st.session_state.progress_queue.put({
            'type': 'progress',
            'progress': progress,
            'task': task
        })
    except:
        pass

def update_log(message: str, level: str = "info"):
    """æ›´æ–°æ—¥å¿—"""
    try:
        st.session_state.progress_queue.put({
            'type': 'log',
            'message': message,
            'level': level
        })
    except:
        pass

async def run_extraction(urls: list, cookie: str, work_path: str):
    """è¿è¡Œè¯„è®ºæå–çš„å¼‚æ­¥å‡½æ•°"""
    try:
        # é€šè¿‡é˜Ÿåˆ—æ›´æ–°çŠ¶æ€
        st.session_state.progress_queue.put({'type': 'status', 'status': 'running'})
        update_log("å¼€å§‹åˆå§‹åŒ–è¯„è®ºæå–å™¨...")
        
        # åˆ›å»ºæå–å™¨å®ä¾‹
        extractor = DynamicCommentExtractor(
            work_path=work_path,
            cookie=cookie,
            use_persistent_session=True
        )
        
        total_urls = len(urls)
        results = []
        
        for i, url in enumerate(urls):
            note_id = extract_note_id_simple(url)
            current_task = f"å¤„ç†ä½œå“ {i+1}/{total_urls}: {note_id}"
            update_progress((i / total_urls) * 100, current_task)
            update_log(f"å¼€å§‹{current_task}")
            
            try:
                # æå–è¯„è®º
                success = await extractor.extract_comments(url)
                
                if success:
                    update_log(f"âœ… ä½œå“ {note_id} å¤„ç†æˆåŠŸ", "success")
                    results.append({
                        'url': url,
                        'note_id': note_id,
                        'status': 'success',
                        'message': 'å¤„ç†æˆåŠŸ'
                    })
                else:
                    update_log(f"âŒ ä½œå“ {note_id} å¤„ç†å¤±è´¥", "error")
                    results.append({
                        'url': url,
                        'note_id': note_id,
                        'status': 'failed',
                        'message': 'å¤„ç†å¤±è´¥'
                    })
            except Exception as e:
                update_log(f"âŒ ä½œå“ {note_id} å‘ç”Ÿå¼‚å¸¸: {str(e)}", "error")
                results.append({
                    'url': url,
                    'note_id': note_id,
                    'status': 'error',
                    'message': f'å¼‚å¸¸: {str(e)}'
                })
        
        # å®Œæˆå¤„ç†
        update_progress(100, "å¤„ç†å®Œæˆ")
        st.session_state.progress_queue.put({'type': 'status', 'status': 'completed'})
        st.session_state.progress_queue.put({'type': 'results', 'results': results})
        success_count = len([r for r in results if r['status'] == 'success'])
        update_log(f"ğŸ‰ æ‰€æœ‰ä½œå“å¤„ç†å®Œæˆï¼æˆåŠŸ: {success_count}/{total_urls}", "success")
        
    except Exception as e:
        st.session_state.progress_queue.put({'type': 'status', 'status': 'error'})
        update_log(f"âŒ æå–è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {str(e)}", "error")

def run_extraction_sync(urls: list, cookie: str, work_path: str):
    """åŒæ­¥åŒ…è£…å™¨ï¼Œç”¨äºåœ¨çº¿ç¨‹ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°"""
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        loop.run_until_complete(run_extraction(urls, cookie, work_path))
    finally:
        loop.close()

def main():
    """ä¸»ç•Œé¢å‡½æ•°"""
    init_session_state()
    
    # ä¸»æ ‡é¢˜
    st.title("ğŸ–¼ï¸ å°çº¢ä¹¦è¯„è®ºæå–å™¨")
    st.markdown("---")
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("âš™ï¸ é…ç½®è®¾ç½®")
        
        # Cookieè¾“å…¥
        st.subheader("1. Cookieè®¾ç½®")
        cookie_input = st.text_area(
            "è¯·è¾“å…¥å°çº¢ä¹¦Cookie:",
            height=100,
            help="ç”¨äºç™»å½•éªŒè¯ï¼Œå¯åœ¨æµè§ˆå™¨å¼€å‘è€…å·¥å…·ä¸­è·å–"
        )
        
        # è¾“å‡ºè·¯å¾„è®¾ç½®
        st.subheader("2. è¾“å‡ºè®¾ç½®")
        work_path = st.text_input(
            "è¾“å‡ºç›®å½•:",
            value="Comments_Dynamic",
            help="è¯„è®ºå’Œå›¾ç‰‡çš„ä¿å­˜ç›®å½•"
        )
        
        # åŠŸèƒ½è¯´æ˜
        st.subheader("ğŸ“‹ åŠŸèƒ½è¯´æ˜")
        st.markdown("""
        **æœ¬å·¥å…·æ”¯æŒï¼š**
        - ğŸ–¼ï¸ è‡ªåŠ¨ä¸‹è½½è¯„è®ºå›¾ç‰‡
        - ğŸ“ æ™ºèƒ½æ–‡ä»¶å‘½å
        - ğŸ“ æœ‰åºæ–‡ä»¶ç»„ç»‡
        - ğŸ” æŒä¹…åŒ–ç™»å½•çŠ¶æ€
        - ğŸ“„ åˆ†é¡µè·å–å…¨éƒ¨è¯„è®º
        """)
    
    # ä¸»å†…å®¹åŒºåŸŸ
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸ“ ä½œå“é“¾æ¥è¾“å…¥")
        
        # é“¾æ¥è¾“å…¥æ–¹å¼é€‰æ‹©
        input_method = st.radio(
            "é€‰æ‹©è¾“å…¥æ–¹å¼:",
            ["å•ä¸ªé“¾æ¥", "æ‰¹é‡é“¾æ¥"],
            horizontal=True
        )
        
        urls = []
        
        if input_method == "å•ä¸ªé“¾æ¥":
            url_input = st.text_input(
                "å°çº¢ä¹¦ä½œå“é“¾æ¥:",
                placeholder="https://www.xiaohongshu.com/explore/...",
                help="è¯·è¾“å…¥å®Œæ•´çš„å°çº¢ä¹¦ä½œå“é“¾æ¥"
            )
            if url_input:
                urls = [url_input]
        else:
            url_input = st.text_area(
                "æ‰¹é‡é“¾æ¥è¾“å…¥ (æ¯è¡Œä¸€ä¸ª):",
                height=150,
                placeholder="https://www.xiaohongshu.com/explore/...\nhttps://www.xiaohongshu.com/explore/...",
                help="æ¯è¡Œè¾“å…¥ä¸€ä¸ªå°çº¢ä¹¦ä½œå“é“¾æ¥"
            )
            if url_input:
                urls = [url.strip() for url in url_input.split('\n') if url.strip()]
        
        # URLéªŒè¯å’Œæ˜¾ç¤º
        if urls:
            st.subheader("ğŸ” é“¾æ¥éªŒè¯")
            valid_urls = []
            for i, url in enumerate(urls):
                col_status, col_url, col_id = st.columns([1, 3, 1])
                
                is_valid = validate_xhs_url(url)
                with col_status:
                    if is_valid:
                        st.success("âœ… æœ‰æ•ˆ")
                        valid_urls.append(url)
                    else:
                        st.error("âŒ æ— æ•ˆ")
                
                with col_url:
                    st.text(url[:80] + "..." if len(url) > 80 else url)
                
                with col_id:
                    if is_valid:
                        note_id = extract_note_id_simple(url)
                        st.code(note_id[:12])
            
            urls = valid_urls
        
        # å¼€å§‹æå–æŒ‰é’®
        st.markdown("---")
        
        can_start = (
            len(urls) > 0 and 
            cookie_input.strip() and 
            st.session_state.extraction_status != 'running'
        )
        
        if st.button(
            f"ğŸš€ å¼€å§‹æå–è¯„è®º ({len(urls)} ä¸ªä½œå“)" if urls else "ğŸš€ å¼€å§‹æå–è¯„è®º",
            disabled=not can_start,
            type="primary"
        ):
            if not cookie_input.strip():
                st.error("è¯·å…ˆè¾“å…¥Cookie!")
            elif not urls:
                st.error("è¯·å…ˆè¾“å…¥æœ‰æ•ˆçš„ä½œå“é“¾æ¥!")
            else:
                # é‡ç½®çŠ¶æ€
                st.session_state.extraction_status = 'idle'
                st.session_state.extraction_progress = 0
                st.session_state.current_task = ""
                st.session_state.extraction_logs = []
                st.session_state.results = None
                # æ¸…ç©ºé˜Ÿåˆ—
                while not st.session_state.progress_queue.empty():
                    try:
                        st.session_state.progress_queue.get_nowait()
                    except:
                        break
                
                # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œæå–
                executor = ThreadPoolExecutor(max_workers=1)
                executor.submit(run_extraction_sync, urls, cookie_input.strip(), work_path)
                
                st.rerun()
    
    with col2:
        st.header("ğŸ“Š æå–çŠ¶æ€")
        
        # å¤„ç†é˜Ÿåˆ—ä¸­çš„æ›´æ–°
        updates_processed = 0
        while not st.session_state.progress_queue.empty() and updates_processed < 100:
            try:
                update = st.session_state.progress_queue.get_nowait()
                updates_processed += 1
                
                if update['type'] == 'status':
                    st.session_state.extraction_status = update['status']
                elif update['type'] == 'progress':
                    st.session_state.extraction_progress = update['progress']
                    st.session_state.current_task = update['task']
                elif update['type'] == 'log':
                    add_log(update['message'], update['level'])
                elif update['type'] == 'results':
                    st.session_state.results = update['results']
            except:
                break
        
        # çŠ¶æ€æŒ‡ç¤ºå™¨
        if st.session_state.extraction_status == 'idle':
            st.info("ç­‰å¾…å¼€å§‹...")
        elif st.session_state.extraction_status == 'running':
            st.warning("æ­£åœ¨æå–ä¸­...")
            
            # è¿›åº¦æ¡
            progress_bar = st.progress(st.session_state.extraction_progress / 100)
            st.write(f"è¿›åº¦: {st.session_state.extraction_progress:.1f}%")
            
            # å½“å‰ä»»åŠ¡
            if st.session_state.current_task:
                st.write(f"å½“å‰ä»»åŠ¡: {st.session_state.current_task}")
            
            # è‡ªåŠ¨åˆ·æ–°
            time.sleep(2)
            st.rerun()
            
        elif st.session_state.extraction_status == 'completed':
            st.success("âœ… æå–å®Œæˆ!")
        elif st.session_state.extraction_status == 'error':
            st.error("âŒ æå–å¤±è´¥!")
        
        # æ—¥å¿—æ˜¾ç¤º
        if st.session_state.extraction_logs:
            st.subheader("ğŸ“‹ å¤„ç†æ—¥å¿—")
            
            # åˆ›å»ºæ—¥å¿—å®¹å™¨
            log_container = st.container()
            
            with log_container:
                # åªæ˜¾ç¤ºæœ€æ–°çš„10æ¡æ—¥å¿—
                recent_logs = st.session_state.extraction_logs[-10:]
                
                for log in recent_logs:
                    if log['level'] == 'success':
                        st.success(f"{log['time']} - {log['message']}")
                    elif log['level'] == 'error':
                        st.error(f"{log['time']} - {log['message']}")
                    else:
                        st.info(f"{log['time']} - {log['message']}")
    
    # ç»“æœæ˜¾ç¤º
    if st.session_state.results:
        st.markdown("---")
        st.header("ğŸ“ˆ æå–ç»“æœ")
        
        # ç»“æœç»Ÿè®¡
        total = len(st.session_state.results)
        success_count = len([r for r in st.session_state.results if r['status'] == 'success'])
        failed_count = total - success_count
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æ€»æ•°", total)
        with col2:
            st.metric("æˆåŠŸ", success_count, delta=None, delta_color="normal")
        with col3:
            st.metric("å¤±è´¥", failed_count, delta=None, delta_color="inverse")
        
        # è¯¦ç»†ç»“æœè¡¨æ ¼
        st.subheader("è¯¦ç»†ç»“æœ")
        result_data = []
        for result in st.session_state.results:
            status_emoji = "âœ…" if result['status'] == 'success' else "âŒ"
            result_data.append({
                'çŠ¶æ€': f"{status_emoji} {result['status']}",
                'ä½œå“ID': result['note_id'],
                'é“¾æ¥': result['url'][:50] + "..." if len(result['url']) > 50 else result['url'],
                'æ¶ˆæ¯': result['message']
            })
        
        st.dataframe(result_data, use_container_width=True)
        
        # è¾“å‡ºç›®å½•ä¿¡æ¯
        output_path = Path(work_path)
        if output_path.exists():
            st.subheader("ğŸ“‚ è¾“å‡ºç›®å½•")
            st.code(str(output_path.absolute()))
            
            # åˆ—å‡ºç”Ÿæˆçš„æ–‡ä»¶å¤¹
            if list(output_path.iterdir()):
                st.write("ç”Ÿæˆçš„æ–‡ä»¶å¤¹:")
                for item in output_path.iterdir():
                    if item.is_dir() and not item.name.startswith('.'):
                        st.write(f"ğŸ“ {item.name}")

if __name__ == "__main__":
    main()