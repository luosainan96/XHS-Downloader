#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½è¯„è®ºé€‰æ‹©å™¨
ç”¨äºç­›é€‰å’Œä¼˜å…ˆæ’åºé€‚åˆAIå›å¤çš„è¯„è®º
"""

import asyncio
import json
import secrets
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from enum import Enum

from local_comment_loader import LocalCommentLoader
from intelligent_reply_generator import IntelligentReplyGenerator
from comment_status_manager import CommentStatusManager, CommentStatus
try:
    from utils.error_handler import (
        with_error_handling, ErrorContext, DataValidationError
    )
    from utils.file_operations import safe_file_ops
    from utils.logging_utils import get_logger, get_performance_logger
    from utils.performance_utils import batch_processor
    UTILS_AVAILABLE = True
except ImportError:
    UTILS_AVAILABLE = False
    # é™çº§å¤„ç†
    def with_error_handling(*args, **kwargs):
        def decorator(func):
            return func
        return decorator
    
    class ErrorContext:
        def __init__(self, *args, **kwargs):
            pass
    
    class DataValidationError(Exception):
        pass
    
    class MockSafeFileOps:
        def write_json_safe(self, path, data, backup=True):
            try:
                with open(path, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)
                return True
            except:
                return False
        
        def read_json_safe(self, path, default=None):
            try:
                with open(path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                return default
    
    safe_file_ops = MockSafeFileOps()
    
    class MockLogger:
        def info(self, *args, **kwargs): pass
        def error(self, *args, **kwargs): pass
        def warning(self, *args, **kwargs): pass
        def debug(self, *args, **kwargs): pass
    
    def get_logger(name):
        return MockLogger()
    
    def get_performance_logger(name):
        def decorator(operation=None):
            def inner_decorator(func):
                return func
            return inner_decorator
        return decorator
    
    batch_processor = None


class CommentPriority(Enum):
    """è¯„è®ºä¼˜å…ˆçº§"""
    HIGH = "high"       # é«˜ä¼˜å…ˆçº§ - æ”¹é€ éœ€æ±‚æ˜ç¡®ä¸”æœ‰å›¾ç‰‡
    MEDIUM = "medium"   # ä¸­ç­‰ä¼˜å…ˆçº§ - æœ‰æ”¹é€ éœ€æ±‚æˆ–æœ‰å›¾ç‰‡
    LOW = "low"         # ä½ä¼˜å…ˆçº§ - ä¸€èˆ¬è¯¢é—®


class SelectionCriteria(Enum):
    """é€‰æ‹©æ ‡å‡†"""
    RENOVATION_REQUESTS = "renovation_requests"     # æ”¹é€ éœ€æ±‚ç±»
    IMAGE_CONSULTATIONS = "image_consultations"     # å›¾ç‰‡å’¨è¯¢ç±»
    HIGH_ENGAGEMENT = "high_engagement"             # é«˜äº’åŠ¨æ½œåŠ›
    RECENT_COMMENTS = "recent_comments"             # æœ€æ–°è¯„è®º
    UNPROCESSED_ONLY = "unprocessed_only"          # æœªå¤„ç†è¯„è®º
    # æ–°å¢çŠ¶æ€ç­›é€‰
    STATUS_PENDING = "status_pending"               # å¾…å¤„ç†çŠ¶æ€
    STATUS_WATCHING = "status_watching"             # è§‚å¯Ÿä¸­çŠ¶æ€
    STATUS_COMPLETED = "status_completed"           # å·²å®ŒæˆçŠ¶æ€


@dataclass
class CommentAnalysis:
    """è¯„è®ºåˆ†æç»“æœ"""
    comment_id: str
    priority: CommentPriority
    renovation_score: int
    processing_recommendation: str
    estimated_cost: float
    keywords_matched: List[str]
    has_quality_images: bool
    reply_potential: float  # 0-1ä¹‹é—´ï¼Œå›å¤æ½œåŠ›è¯„åˆ†


class CommentSelector:
    """æ™ºèƒ½è¯„è®ºé€‰æ‹©å™¨"""
    
    def __init__(self, work_path: str = "Comments_Dynamic"):
        self.work_path = Path(work_path)
        self.selection_history_path = self.work_path / "selection_history"
        self.selection_history_path.mkdir(parents=True, exist_ok=True)
        
        self.comment_loader = LocalCommentLoader(work_path)
        self.status_manager = CommentStatusManager(work_path)
        
        # å®¶å±…æ”¹é€ å…³é”®è¯æƒé‡
        self.renovation_keywords = {
            # é«˜æƒé‡å…³é”®è¯ (10åˆ†)
            'æ”¹é€ ': 10, 'è£…ä¿®': 10, 'è®¾è®¡': 10, 'ç¿»æ–°': 10,
            # ä¸­æƒé‡å…³é”®è¯ (7åˆ†)
            'æ”¶çº³': 7, 'å¸ƒå±€': 7, 'é£æ ¼': 7, 'æ­é…': 7,
            # æˆ¿é—´ç±»å‹ (5åˆ†)
            'å®¢å…': 5, 'å§å®¤': 5, 'å¨æˆ¿': 5, 'å«ç”Ÿé—´': 5, 'ä¹¦æˆ¿': 5,
            'å‡ºç§Ÿå±‹': 5, 'å°æˆ·å‹': 5, 'æ–°æˆ¿': 5, 'äºŒæ‰‹æˆ¿': 5,
            # å®¶å…·ç±»å‹ (3åˆ†)
            'å®¶å…·': 3, 'æ²™å‘': 3, 'åºŠ': 3, 'æ¡Œå­': 3, 'æŸœå­': 3,
            'çª—å¸˜': 3, 'ç¯å…·': 3, 'åœ°æ¿': 3, 'å¢™é¢': 3,
            # é¢„ç®—ç›¸å…³ (8åˆ†)
            'é¢„ç®—': 8, 'ä¾¿å®œ': 5, 'æ€§ä»·æ¯”': 6, 'diy': 6,
            # é—®é¢˜æè¿° (6åˆ†)
            'æ±‚åŠ©': 6, 'å¸®å¿™': 6, 'å»ºè®®': 6, 'æ¨è': 6, 'æ€ä¹ˆ': 6
        }
        
        # è´¨é‡è¯„ä¼°å…³é”®è¯
        self.quality_keywords = {
            'è¯¦ç»†': 3, 'å…·ä½“': 3, 'ä¸“ä¸š': 5, 'ç»éªŒ': 4,
            'è°¢è°¢': 2, 'è¯·é—®': 3, 'éº»çƒ¦': 3, 'æ„Ÿè°¢': 2
        }
        
    async def analyze_comment(self, comment_data: Dict) -> CommentAnalysis:
        """åˆ†æå•ä¸ªè¯„è®ºçš„å›å¤æ½œåŠ›"""
        
        content = comment_data.get('content', '').lower()
        images = comment_data.get('downloaded_images', [])
        nickname = comment_data.get('nickname', '')
        
        # è®¡ç®—æ”¹é€ ç›¸å…³å¾—åˆ†
        renovation_score = 0
        matched_keywords = []
        
        for keyword, weight in self.renovation_keywords.items():
            if keyword in content:
                renovation_score += weight
                matched_keywords.append(keyword)
        
        # å›¾ç‰‡è´¨é‡è¯„ä¼°
        has_quality_images = len(images) > 0
        if has_quality_images:
            renovation_score += 20  # æœ‰å›¾ç‰‡åŠ åˆ†
            if len(images) > 1:
                renovation_score += 10  # å¤šå›¾ç‰‡é¢å¤–åŠ åˆ†
        
        # å†…å®¹è´¨é‡è¯„ä¼°
        content_quality_score = 0
        for keyword, weight in self.quality_keywords.items():
            if keyword in content:
                content_quality_score += weight
        
        # å†…å®¹é•¿åº¦è¯„ä¼°
        content_length = len(content)
        if content_length > 50:
            content_quality_score += 5
        if content_length > 100:
            content_quality_score += 5
        
        # è®¡ç®—æ€»ä½“å›å¤æ½œåŠ› (0-1ä¹‹é—´)
        base_potential = min(renovation_score / 100, 1.0)  # åŸºç¡€æ½œåŠ›
        quality_bonus = min(content_quality_score / 20, 0.3)  # è´¨é‡åŠ æˆ
        reply_potential = min(base_potential + quality_bonus, 1.0)
        
        # ç¡®å®šä¼˜å…ˆçº§
        if renovation_score >= 40 and has_quality_images:
            priority = CommentPriority.HIGH
            recommendation = "å¼ºçƒˆæ¨èAIå›å¤ - æ˜ç¡®æ”¹é€ éœ€æ±‚ä¸”æœ‰å‚è€ƒå›¾ç‰‡"
            estimated_cost = 0.5
        elif renovation_score >= 25 or has_quality_images:
            priority = CommentPriority.MEDIUM
            recommendation = "æ¨èAIå›å¤ - æœ‰æ”¹é€ æ½œåŠ›æˆ–å›¾ç‰‡å‚è€ƒ"
            estimated_cost = 0.3
        elif renovation_score >= 15:
            priority = CommentPriority.MEDIUM
            recommendation = "å¯é€‰AIå›å¤ - è½»åº¦æ”¹é€ ç›¸å…³"
            estimated_cost = 0.2
        else:
            priority = CommentPriority.LOW
            recommendation = "ä¸€èˆ¬å›å¤ - ä½¿ç”¨æ¨¡æ¿å›å¤å³å¯"
            estimated_cost = 0.1
        
        # ç”Ÿæˆå”¯ä¸€ID
        comment_id = f"{nickname}_{comment_data.get('time', '')}".replace(' ', '_').replace(':', '-')
        
        return CommentAnalysis(
            comment_id=comment_id,
            priority=priority,
            renovation_score=renovation_score,
            processing_recommendation=recommendation,
            estimated_cost=estimated_cost,
            keywords_matched=matched_keywords,
            has_quality_images=has_quality_images,
            reply_potential=reply_potential
        )
    
    async def select_comments_by_criteria(self, work_dir: str, 
                                        criteria: SelectionCriteria,
                                        limit: int = 20,
                                        min_priority: CommentPriority = CommentPriority.LOW) -> List[Tuple[Dict, CommentAnalysis]]:
        """æ ¹æ®é€‰æ‹©æ ‡å‡†ç­›é€‰è¯„è®º"""
        
        # åŠ è½½æ‰€æœ‰è¯„è®º
        comments = self.comment_loader.load_comments_from_work(work_dir)
        
        # åˆ†ææ‰€æœ‰è¯„è®º
        analyzed_comments = []
        for comment in comments:
            analysis = await self.analyze_comment(comment)
            
            # åº”ç”¨æœ€ä½ä¼˜å…ˆçº§è¿‡æ»¤
            priority_order = {CommentPriority.HIGH: 3, CommentPriority.MEDIUM: 2, CommentPriority.LOW: 1}
            if priority_order[analysis.priority] >= priority_order[min_priority]:
                analyzed_comments.append((comment, analysis))
        
        # æ ¹æ®é€‰æ‹©æ ‡å‡†è¿›è¡Œç­›é€‰å’Œæ’åº
        if criteria == SelectionCriteria.RENOVATION_REQUESTS:
            # æŒ‰æ”¹é€ å¾—åˆ†æ’åº
            analyzed_comments.sort(key=lambda x: x[1].renovation_score, reverse=True)
            analyzed_comments = [item for item in analyzed_comments if item[1].renovation_score >= 20]
            
        elif criteria == SelectionCriteria.IMAGE_CONSULTATIONS:
            # ç­›é€‰æœ‰å›¾ç‰‡çš„è¯„è®º
            analyzed_comments = [item for item in analyzed_comments if item[1].has_quality_images]
            analyzed_comments.sort(key=lambda x: len(x[0].get('downloaded_images', [])), reverse=True)
            
        elif criteria == SelectionCriteria.HIGH_ENGAGEMENT:
            # æŒ‰å›å¤æ½œåŠ›æ’åº
            analyzed_comments.sort(key=lambda x: x[1].reply_potential, reverse=True)
            analyzed_comments = [item for item in analyzed_comments if item[1].reply_potential >= 0.3]
            
        elif criteria == SelectionCriteria.RECENT_COMMENTS:
            # æŒ‰æ—¶é—´æ’åºï¼ˆæœ€æ–°ä¼˜å…ˆï¼‰
            analyzed_comments.sort(key=lambda x: x[0].get('create_time', 0), reverse=True)
            
        elif criteria == SelectionCriteria.UNPROCESSED_ONLY:
            # ç­›é€‰æœªå¤„ç†çš„è¯„è®ºï¼ˆè¿™é‡Œéœ€è¦ä¸æ™ºèƒ½å›å¤å†å²å¯¹æ¯”ï¼‰
            processed_ids = await self.get_processed_comment_ids()
            analyzed_comments = [
                item for item in analyzed_comments 
                if item[1].comment_id not in processed_ids
            ]
            analyzed_comments.sort(key=lambda x: x[1].priority.value == 'high', reverse=True)
            
        elif criteria == SelectionCriteria.STATUS_PENDING:
            # ç­›é€‰å¾…å¤„ç†çŠ¶æ€çš„è¯„è®º
            analyzed_comments = self.filter_by_comment_status(analyzed_comments, CommentStatus.PENDING)
            
        elif criteria == SelectionCriteria.STATUS_WATCHING:
            # ç­›é€‰è§‚å¯Ÿä¸­çŠ¶æ€çš„è¯„è®º
            analyzed_comments = self.filter_by_comment_status(analyzed_comments, CommentStatus.WATCHING)
            
        elif criteria == SelectionCriteria.STATUS_COMPLETED:
            # ç­›é€‰å·²å®ŒæˆçŠ¶æ€çš„è¯„è®º
            analyzed_comments = self.filter_by_comment_status(analyzed_comments, CommentStatus.COMPLETED)
        
        return analyzed_comments[:limit]
    
    def filter_by_comment_status(self, analyzed_comments: List[Tuple[Dict, CommentAnalysis]], 
                                target_status: CommentStatus) -> List[Tuple[Dict, CommentAnalysis]]:
        """æ ¹æ®è¯„è®ºçŠ¶æ€ç­›é€‰"""
        filtered_comments = []
        
        for comment, analysis in analyzed_comments:
            # ç”Ÿæˆè¯„è®ºIDç”¨äºçŠ¶æ€æŸ¥æ‰¾
            user_nickname = comment.get('nickname', '')
            content = comment.get('content', '')
            
            # æŸ¥æ‰¾æˆ–åˆ›å»ºçŠ¶æ€è®°å½•
            comment_id = self.status_manager.generate_comment_id(
                user_nickname, 
                "å½“å‰ä½œå“",  # è¿™é‡Œå¯ä»¥ä¼ å…¥å®é™…çš„ä½œå“æ ‡é¢˜
                content
            )
            
            # æ£€æŸ¥çŠ¶æ€è®°å½•
            status_record = self.status_manager.get_comment_status(comment_id)
            
            if status_record:
                # å¦‚æœçŠ¶æ€åŒ¹é…åˆ™åŒ…å«
                if status_record.status == target_status:
                    filtered_comments.append((comment, analysis))
            else:
                # å¦‚æœæ²¡æœ‰çŠ¶æ€è®°å½•ï¼Œä¸”ç­›é€‰çš„æ˜¯å¾…å¤„ç†çŠ¶æ€ï¼Œåˆ™åŒ…å«
                if target_status == CommentStatus.PENDING:
                    filtered_comments.append((comment, analysis))
        
        return filtered_comments
    
    def ensure_comment_status_exists(self, work_dir: str, work_title: str):
        """ç¡®ä¿è¯„è®ºçŠ¶æ€è®°å½•å­˜åœ¨"""
        # è‡ªåŠ¨å¯¼å…¥å½“å‰ä½œå“çš„è¯„è®ºçŠ¶æ€
        imported_count = self.status_manager.import_comments_from_local_data(work_dir, work_title)
        if imported_count > 0:
            print(f"è‡ªåŠ¨å¯¼å…¥äº† {imported_count} æ¡è¯„è®ºçŠ¶æ€è®°å½•")
    
    async def get_processed_comment_ids(self) -> set:
        """è·å–å·²å¤„ç†çš„è¯„è®ºIDé›†åˆ"""
        processed_ids = set()
        
        # æ‰«ææ™ºèƒ½å›å¤å†å²è®°å½•
        reply_history_path = self.work_path / "intelligent_replies"
        if reply_history_path.exists():
            for result_file in reply_history_path.glob("*_result.json"):
                try:
                    with open(result_file, 'r', encoding='utf-8') as f:
                        result = json.load(f)
                        comment_data = result.get('comment_data', {})
                        nickname = comment_data.get('nickname', '')
                        time_str = comment_data.get('time', '')
                        comment_id = f"{nickname}_{time_str}".replace(' ', '_').replace(':', '-')
                        processed_ids.add(comment_id)
                except Exception:
                    continue
        
        return processed_ids
    
    def __init__(self, work_path: str = "Comments_Dynamic"):
        self.work_path = Path(work_path)
        self.selection_history_path = self.work_path / "selection_history"
        self.selection_history_path.mkdir(parents=True, exist_ok=True)
        
        self.comment_loader = LocalCommentLoader(work_path)
        self.status_manager = CommentStatusManager(work_path)
        
        if UTILS_AVAILABLE:
            self.logger = get_logger("comment_selector")
            self.perf_logger = get_performance_logger("comment_selector")
        else:
            self.logger = MockLogger()
            self.perf_logger = get_performance_logger("comment_selector")
        
        # åˆå§‹åŒ–å…³é”®è¯æƒé‡
        self._init_keywords()
    
    def _init_keywords(self):
        """åˆå§‹åŒ–å…³é”®è¯æƒé‡"""
        # å®¶å±…æ”¹é€ å…³é”®è¯æƒé‡
        self.renovation_keywords = {
            # é«˜æƒé‡å…³é”®è¯ (10åˆ†)
            'æ”¹é€ ': 10, 'è£…ä¿®': 10, 'è®¾è®¡': 10, 'ç¿»æ–°': 10,
            # ä¸­æƒé‡å…³é”®è¯ (7åˆ†)
            'æ”¶çº³': 7, 'å¸ƒå±€': 7, 'é£æ ¼': 7, 'æ­é…': 7,
            # æˆ¿é—´ç±»å‹ (5åˆ†)
            'å®¢å…': 5, 'å§å®¤': 5, 'å¨æˆ¿': 5, 'å«ç”Ÿé—´': 5, 'ä¹¦æˆ¿': 5,
            'å‡ºç§Ÿå±‹': 5, 'å°æˆ·å‹': 5, 'æ–°æˆ¿': 5, 'äºŒæ‰‹æˆ¿': 5,
            # å®¶å…·ç±»å‹ (3åˆ†)
            'å®¶å…·': 3, 'æ²™å‘': 3, 'åºŠ': 3, 'æ¡Œå­': 3, 'æŸœå­': 3,
            'çª—å¸˜': 3, 'ç¯å…·': 3, 'åœ°æ¿': 3, 'å¢™é¢': 3,
            # é¢„ç®—ç›¸å…³ (8åˆ†)
            'é¢„ç®—': 8, 'ä¾¿å®œ': 5, 'æ€§ä»·æ¯”': 6, 'diy': 6,
            # é—®é¢˜æè¿° (6åˆ†)
            'æ±‚åŠ©': 6, 'å¸®å¿™': 6, 'å»ºè®®': 6, 'æ¨è': 6, 'æ€ä¹ˆ': 6
        }
        
        # è´¨é‡è¯„ä¼°å…³é”®è¯
        self.quality_keywords = {
            'è¯¦ç»†': 3, 'å…·ä½“': 3, 'ä¸“ä¸š': 5, 'ç»éªŒ': 4,
            'è°¢è°¢': 2, 'è¯·é—®': 3, 'éº»çƒ¦': 3, 'æ„Ÿè°¢': 2
        }
    
    @with_error_handling(
        context=ErrorContext("create_selection_batch", "comment_selector")
    )
    async def create_selection_batch(self, work_dir: str, 
                                   criteria_list: List[SelectionCriteria],
                                   total_limit: int = 50) -> Dict:
        """åˆ›å»ºé€‰æ‹©æ‰¹æ¬¡ï¼Œç»¼åˆå¤šä¸ªæ ‡å‡†"""
        
        batch_id = self._generate_batch_id()
        batch_result = self._init_batch_result(batch_id, work_dir, criteria_list)
        
        # æŒ‰ä¸åŒæ ‡å‡†é€‰æ‹©è¯„è®º
        all_selected = await self._select_by_criteria(work_dir, criteria_list, total_limit, batch_result)
        
        # å»é‡å¹¶æ’åº
        final_selections = self._deduplicate_and_sort(all_selected, total_limit)
        
        # ç”Ÿæˆæ‘˜è¦å’Œæœ€ç»ˆç»“æœ
        batch_result["summary"] = self._generate_summary(final_selections)
        batch_result["final_selections"] = self._format_final_selections(final_selections)
        
        # ä¿å­˜æ‰¹æ¬¡ç»“æœ
        await self.save_selection_batch(batch_result)
        
        return batch_result
    
    def _generate_batch_id(self) -> str:
        """ç”Ÿæˆæ‰¹æ¬¡ID"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        random_suffix = secrets.token_hex(4)
        return f"{timestamp}_{random_suffix}"
    
    def _init_batch_result(self, batch_id: str, work_dir: str, 
                          criteria_list: List[SelectionCriteria]) -> Dict:
        """åˆå§‹åŒ–æ‰¹æ¬¡ç»“æœç»“æ„"""
        return {
            "batch_id": batch_id,
            "work_dir": work_dir,
            "timestamp": datetime.now().isoformat(),
            "criteria_used": [c.value for c in criteria_list],
            "selections": {},
            "summary": {}
        }
    
    async def _select_by_criteria(self, work_dir: str, criteria_list: List[SelectionCriteria],
                                 total_limit: int, batch_result: Dict) -> List[Tuple]:
        """æŒ‰ä¸åŒæ ‡å‡†é€‰æ‹©è¯„è®º"""
        all_selected = []
        
        for criteria in criteria_list:
            limit_per_criteria = max(total_limit // len(criteria_list) + 5, 10)
            selected = await self.select_comments_by_criteria(
                work_dir, criteria, limit=limit_per_criteria
            )
            
            # è®°å½•æ¯ä¸ªæ ‡å‡†çš„é€‰æ‹©ç»“æœ
            batch_result["selections"][criteria.value] = [
                self._create_selection_item(comment, analysis)
                for comment, analysis in selected
            ]
            
            all_selected.extend(selected)
        
        return all_selected
    
    def _create_selection_item(self, comment: Dict, analysis) -> Dict:
        """åˆ›å»ºé€‰æ‹©é¡¹ç›®"""
        return {
            "comment_id": analysis.comment_id,
            "nickname": comment.get('nickname', ''),
            "content_preview": self._truncate_content(comment.get('content', '')),
            "priority": analysis.priority.value,
            "renovation_score": analysis.renovation_score,
            "reply_potential": analysis.reply_potential,
            "estimated_cost": analysis.estimated_cost,
            "has_images": analysis.has_quality_images,
            "keywords_matched": analysis.keywords_matched,
            "recommendation": analysis.processing_recommendation
        }
    
    def _truncate_content(self, content: str, max_length: int = 100) -> str:
        """æˆªæ–­å†…å®¹é¢„è§ˆ"""
        if len(content) <= max_length:
            return content
        return content[:max_length] + "..."
    
    def _deduplicate_and_sort(self, all_selected: List[Tuple], total_limit: int) -> List[Tuple]:
        """å»é‡å¹¶æŒ‰ä¼˜å…ˆçº§æ’åº"""
        # å»é‡
        unique_selections = {}
        for comment, analysis in all_selected:
            if analysis.comment_id not in unique_selections:
                unique_selections[analysis.comment_id] = (comment, analysis)
        
        # æ’åº
        final_selections = list(unique_selections.values())
        final_selections.sort(
            key=lambda x: (
                x[1].priority.value == 'high',
                x[1].reply_potential,
                x[1].renovation_score
            ), 
            reverse=True
        )
        
        return final_selections[:total_limit]
    
    def _generate_summary(self, final_selections: List[Tuple]) -> Dict:
        """ç”Ÿæˆæ‰¹æ¬¡æ‘˜è¦"""
        if not final_selections:
            return {
                "total_selected": 0,
                "high_priority_count": 0,
                "medium_priority_count": 0,
                "low_priority_count": 0,
                "total_estimated_cost": 0.0,
                "average_renovation_score": 0.0,
                "images_available": 0
            }
        
        priority_counts = {
            CommentPriority.HIGH: 0,
            CommentPriority.MEDIUM: 0,
            CommentPriority.LOW: 0
        }
        
        total_cost = 0.0
        total_score = 0.0
        images_count = 0
        
        for _, analysis in final_selections:
            priority_counts[analysis.priority] += 1
            total_cost += analysis.estimated_cost
            total_score += analysis.renovation_score
            if analysis.has_quality_images:
                images_count += 1
        
        return {
            "total_selected": len(final_selections),
            "high_priority_count": priority_counts[CommentPriority.HIGH],
            "medium_priority_count": priority_counts[CommentPriority.MEDIUM],
            "low_priority_count": priority_counts[CommentPriority.LOW],
            "total_estimated_cost": round(total_cost, 2),
            "average_renovation_score": round(total_score / len(final_selections), 1),
            "images_available": images_count
        }
    
    def _format_final_selections(self, final_selections: List[Tuple]) -> List[Dict]:
        """æ ¼å¼åŒ–æœ€ç»ˆé€‰æ‹©ç»“æœ"""
        return [
            {
                "comment_data": comment,
                "analysis": {
                    "comment_id": analysis.comment_id,
                    "priority": analysis.priority.value,
                    "renovation_score": analysis.renovation_score,
                    "reply_potential": analysis.reply_potential,
                    "estimated_cost": analysis.estimated_cost,
                    "has_quality_images": analysis.has_quality_images,
                    "keywords_matched": analysis.keywords_matched,
                    "processing_recommendation": analysis.processing_recommendation
                }
            }
            for comment, analysis in final_selections
        ]
    
    @with_error_handling(
        context=ErrorContext("save_selection_batch", "comment_selector")
    )
    async def save_selection_batch(self, batch_result: Dict) -> bool:
        """ä¿å­˜é€‰æ‹©æ‰¹æ¬¡"""
        batch_id = batch_result["batch_id"]
        save_path = self.selection_history_path / f"batch_{batch_id}.json"
        
        return safe_file_ops.write_json_safe(save_path, batch_result)
    
    @with_error_handling(
        context=ErrorContext("load_selection_batch", "comment_selector"),
        fallback_value=None
    )
    async def load_selection_batch(self, batch_id: str) -> Optional[Dict]:
        """åŠ è½½é€‰æ‹©æ‰¹æ¬¡"""
        save_path = self.selection_history_path / f"batch_{batch_id}.json"
        return safe_file_ops.read_json_safe(save_path)
    
    def get_selection_history(self, limit: int = 20) -> List[Dict]:
        """è·å–é€‰æ‹©å†å²"""
        history_files = sorted(
            self.selection_history_path.glob("batch_*.json"),
            key=lambda x: x.stat().st_mtime,
            reverse=True
        )
        
        history = []
        for file_path in history_files[:limit]:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    batch = json.load(f)
                    history.append({
                        "batch_id": batch["batch_id"],
                        "timestamp": batch["timestamp"],
                        "work_dir": batch["work_dir"],
                        "total_selected": batch["summary"]["total_selected"],
                        "high_priority": batch["summary"]["high_priority_count"],
                        "estimated_cost": batch["summary"]["total_estimated_cost"]
                    })
            except Exception as e:
                print(f"è¯»å–é€‰æ‹©å†å²å¤±è´¥ {file_path}: {e}")
                continue
        
        return history
    
    async def smart_auto_select(self, work_dir: str, 
                              daily_budget: float = 10.0,
                              max_comments: int = 20) -> Dict:
        """æ™ºèƒ½è‡ªåŠ¨é€‰æ‹© - åœ¨é¢„ç®—èŒƒå›´å†…é€‰æ‹©æœ€æœ‰ä»·å€¼çš„è¯„è®º"""
        
        # ç»¼åˆå¤šç§æ ‡å‡†
        criteria_list = [
            SelectionCriteria.RENOVATION_REQUESTS,
            SelectionCriteria.IMAGE_CONSULTATIONS,
            SelectionCriteria.HIGH_ENGAGEMENT,
            SelectionCriteria.UNPROCESSED_ONLY
        ]
        
        # åˆ›å»ºåˆå§‹é€‰æ‹©æ‰¹æ¬¡
        batch = await self.create_selection_batch(work_dir, criteria_list, max_comments * 2)
        
        # åœ¨é¢„ç®—èŒƒå›´å†…ä¼˜åŒ–é€‰æ‹©
        final_selections = []
        current_cost = 0.0
        
        for item in batch["final_selections"]:
            estimated_cost = item["analysis"]["estimated_cost"]
            if current_cost + estimated_cost <= daily_budget:
                final_selections.append(item)
                current_cost += estimated_cost
                
                if len(final_selections) >= max_comments:
                    break
        
        # æ›´æ–°æ‰¹æ¬¡ç»“æœ
        batch["final_selections"] = final_selections
        batch["summary"]["total_selected"] = len(final_selections)
        batch["summary"]["total_estimated_cost"] = round(current_cost, 2)
        batch["summary"]["budget_used_percentage"] = round((current_cost / daily_budget) * 100, 1)
        
        # é‡æ–°ä¿å­˜
        await self.save_selection_batch(batch)
        
        return batch


# æµ‹è¯•å‡½æ•°
async def test_comment_selector():
    """æµ‹è¯•è¯„è®ºé€‰æ‹©å™¨"""
    
    selector = CommentSelector("Comments_Dynamic")
    
    print("ğŸ§ª å¼€å§‹æµ‹è¯•è¯„è®ºé€‰æ‹©å™¨")
    print("="*50)
    
    # è·å–å¯ç”¨ä½œå“
    works = selector.comment_loader.scan_available_works()
    if not works:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„ä½œå“æ•°æ®")
        return
    
    test_work = works[0]
    work_dir = test_work['work_dir']
    
    print(f"ğŸ“ æµ‹è¯•ä½œå“: {test_work['work_title']}")
    print(f"ğŸ“Š è¯„è®ºæ•°é‡: {test_work['comment_count']}")
    
    # æµ‹è¯•ä¸åŒé€‰æ‹©æ ‡å‡†
    criteria_tests = [
        SelectionCriteria.RENOVATION_REQUESTS,
        SelectionCriteria.IMAGE_CONSULTATIONS,
        SelectionCriteria.HIGH_ENGAGEMENT
    ]
    
    for criteria in criteria_tests:
        print(f"\nğŸ” æµ‹è¯•é€‰æ‹©æ ‡å‡†: {criteria.value}")
        selected = await selector.select_comments_by_criteria(work_dir, criteria, limit=5)
        
        print(f"   é€‰æ‹©æ•°é‡: {len(selected)}")
        for i, (comment, analysis) in enumerate(selected[:3]):
            print(f"   {i+1}. {comment['nickname']} - å¾—åˆ†:{analysis.renovation_score} - ä¼˜å…ˆçº§:{analysis.priority.value}")
            print(f"      å†…å®¹é¢„è§ˆ: {comment['content'][:50]}...")
            print(f"      å…³é”®è¯: {', '.join(analysis.keywords_matched[:3])}")
    
    # æµ‹è¯•æ™ºèƒ½è‡ªåŠ¨é€‰æ‹©
    print(f"\nğŸ¤– æµ‹è¯•æ™ºèƒ½è‡ªåŠ¨é€‰æ‹©...")
    auto_batch = await selector.smart_auto_select(work_dir, daily_budget=5.0, max_comments=10)
    
    print(f"   æ‰¹æ¬¡ID: {auto_batch['batch_id']}")
    print(f"   æ€»é€‰æ‹©æ•°: {auto_batch['summary']['total_selected']}")
    print(f"   é¢„ä¼°æˆæœ¬: ${auto_batch['summary']['total_estimated_cost']}")
    print(f"   é¢„ç®—ä½¿ç”¨ç‡: {auto_batch['summary'].get('budget_used_percentage', 0)}%")
    
    # æ˜¾ç¤ºå‰3ä¸ªé€‰æ‹©
    print(f"\nğŸ“‹ å‰3ä¸ªæ¨èè¯„è®º:")
    for i, item in enumerate(auto_batch['final_selections'][:3]):
        comment = item['comment_data']
        analysis = item['analysis']
        print(f"   {i+1}. {comment['nickname']} - {analysis['priority']} ä¼˜å…ˆçº§")
        print(f"      æ”¹é€ å¾—åˆ†: {analysis['renovation_score']}")
        print(f"      å›å¤æ½œåŠ›: {analysis['reply_potential']:.2f}")
        print(f"      é¢„ä¼°æˆæœ¬: ${analysis['estimated_cost']}")
        print(f"      æ¨èç†ç”±: {analysis['processing_recommendation']}")
        print()


if __name__ == "__main__":
    asyncio.run(test_comment_selector())