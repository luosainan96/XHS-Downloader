#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°çº¢ä¹¦è¯„è®ºæå–å™¨ - ä¿®å¤ç‰ˆWeb UIç•Œé¢
è§£å†³ç‚¹å‡»æ— ååº”çš„é—®é¢˜
"""

import asyncio
import streamlit as st
import time
from pathlib import Path
import json
from datetime import datetime
import threading
import re

from dynamic_comment_extractor import DynamicCommentExtractor

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="å°çº¢ä¹¦è¯„è®ºæå–å™¨",
    page_icon="ğŸ–¼ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

def init_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    if 'extraction_status' not in st.session_state:
        st.session_state.extraction_status = 'idle'
    if 'extraction_progress' not in st.session_state:
        st.session_state.extraction_progress = 0
    if 'current_task' not in st.session_state:
        st.session_state.current_task = ""
    if 'extraction_logs' not in st.session_state:
        st.session_state.extraction_logs = []
    if 'results' not in st.session_state:
        st.session_state.results = None
    if 'last_update' not in st.session_state:
        st.session_state.last_update = time.time()

def add_log(message: str, level: str = "info"):
    """æ·»åŠ æ—¥å¿—æ¶ˆæ¯"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    st.session_state.extraction_logs.append({
        'time': timestamp,
        'level': level,
        'message': message
    })
    st.session_state.last_update = time.time()

def validate_xhs_url(url: str) -> bool:
    """éªŒè¯å°çº¢ä¹¦URLæ ¼å¼"""
    if not url:
        return False
    
    if 'xiaohongshu.com' not in url:
        return False
    
    if '/explore/' not in url:
        return False
    
    return True

def extract_note_id_simple(url: str) -> str:
    """ç®€å•æå–ç¬”è®°IDç”¨äºæ˜¾ç¤º"""
    try:
        if '/explore/' in url:
            parts = url.split('/explore/')
            if len(parts) > 1:
                note_part = parts[1].split('?')[0]
                return note_part
    except:
        pass
    return "æœªçŸ¥ID"

def run_extraction_simple(urls: list, cookie: str, work_path: str, max_comments: int = None):
    """ç®€åŒ–çš„æå–å‡½æ•°ï¼Œç›´æ¥åœ¨ä¸»çº¿ç¨‹ä¸­è¿è¡Œ"""
    try:
        st.session_state.extraction_status = 'running'
        if max_comments:
            add_log(f"å¼€å§‹åˆå§‹åŒ–è¯„è®ºæå–å™¨... (é™åˆ¶æ•°é‡: {max_comments})")
        else:
            add_log("å¼€å§‹åˆå§‹åŒ–è¯„è®ºæå–å™¨...")
        
        # åˆ›å»ºä¸€ä¸ªæ–°çš„äº‹ä»¶å¾ªç¯ç”¨äºå¼‚æ­¥æ“ä½œ
        async def async_extraction():
            extractor = DynamicCommentExtractor(
                work_path=work_path,
                cookie=cookie,
                use_persistent_session=True,
                max_comments=max_comments
            )
            
            total_urls = len(urls)
            results = []
            
            for i, url in enumerate(urls):
                note_id = extract_note_id_simple(url)
                current_task = f"å¤„ç†ä½œå“ {i+1}/{total_urls}: {note_id}"
                
                # æ›´æ–°è¿›åº¦
                progress = (i / total_urls) * 100
                st.session_state.extraction_progress = progress
                st.session_state.current_task = current_task
                add_log(f"å¼€å§‹{current_task}")
                
                try:
                    success = await extractor.extract_comments(url)
                    
                    if success:
                        add_log(f"âœ… ä½œå“ {note_id} å¤„ç†æˆåŠŸ", "success")
                        results.append({
                            'url': url,
                            'note_id': note_id,
                            'status': 'success',
                            'message': 'å¤„ç†æˆåŠŸ'
                        })
                    else:
                        add_log(f"âŒ ä½œå“ {note_id} å¤„ç†å¤±è´¥", "error")
                        results.append({
                            'url': url,
                            'note_id': note_id,
                            'status': 'failed',
                            'message': 'å¤„ç†å¤±è´¥'
                        })
                except Exception as e:
                    add_log(f"âŒ ä½œå“ {note_id} å‘ç”Ÿå¼‚å¸¸: {str(e)}", "error")
                    results.append({
                        'url': url,
                        'note_id': note_id,
                        'status': 'error',
                        'message': f'å¼‚å¸¸: {str(e)}'
                    })
            
            # å®Œæˆå¤„ç†
            st.session_state.extraction_progress = 100
            st.session_state.current_task = "å¤„ç†å®Œæˆ"
            st.session_state.extraction_status = 'completed'
            st.session_state.results = results
            
            success_count = len([r for r in results if r['status'] == 'success'])
            add_log(f"ğŸ‰ æ‰€æœ‰ä½œå“å¤„ç†å®Œæˆï¼æˆåŠŸ: {success_count}/{total_urls}", "success")
        
        # åœ¨æ–°çš„äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            loop.run_until_complete(async_extraction())
        finally:
            loop.close()
            
    except Exception as e:
        st.session_state.extraction_status = 'error'
        add_log(f"âŒ æå–è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {str(e)}", "error")

def main():
    """ä¸»ç•Œé¢å‡½æ•°"""
    init_session_state()
    
    # ä¸»æ ‡é¢˜
    st.title("ğŸ–¼ï¸ å°çº¢ä¹¦è¯„è®ºæå–å™¨")
    st.markdown("---")
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("âš™ï¸ é…ç½®è®¾ç½®")
        
        # Cookieè¾“å…¥
        st.subheader("1. Cookieè®¾ç½®")
        cookie_input = st.text_area(
            "è¯·è¾“å…¥å°çº¢ä¹¦Cookie:",
            height=100,
            help="ç”¨äºç™»å½•éªŒè¯ï¼Œå¯åœ¨æµè§ˆå™¨å¼€å‘è€…å·¥å…·ä¸­è·å–",
            placeholder="a1=xxx; web_session=xxx; ..."
        )
        
        # è¾“å‡ºè·¯å¾„è®¾ç½®
        st.subheader("2. è¾“å‡ºè®¾ç½®")
        work_path = st.text_input(
            "è¾“å‡ºç›®å½•:",
            value="Comments_Dynamic",
            help="è¯„è®ºå’Œå›¾ç‰‡çš„ä¿å­˜ç›®å½•"
        )
        
        # è¯„è®ºæ•°é‡é™åˆ¶
        st.subheader("3. è¯„è®ºæ•°é‡è®¾ç½®")
        limit_comments = st.checkbox("é™åˆ¶è¯„è®ºæ•°é‡", value=False, help="å‹¾é€‰ä»¥åªè·å–æœ€æ–°çš„næ¡è¯„è®º")
        
        max_comments = None
        if limit_comments:
            max_comments = st.number_input(
                "æœ€å¤§è¯„è®ºæ•°é‡:",
                min_value=1,
                max_value=500,
                value=50,
                step=1,
                help="åªè·å–æœ€æ–°çš„næ¡è¯„è®ºï¼Œå»ºè®®ä¸è¶…è¿‡100æ¡"
            )
            st.info(f"å°†åªè·å–æœ€æ–°çš„ {max_comments} æ¡è¯„è®º")
        
        # åŠŸèƒ½è¯´æ˜
        st.subheader("ğŸ“‹ åŠŸèƒ½è¯´æ˜")
        st.markdown("""
        **æœ¬å·¥å…·æ”¯æŒï¼š**
        - ğŸ–¼ï¸ è‡ªåŠ¨ä¸‹è½½è¯„è®ºå›¾ç‰‡
        - ğŸ“ æ™ºèƒ½æ–‡ä»¶å‘½å
        - ğŸ“ æœ‰åºæ–‡ä»¶ç»„ç»‡
        - ğŸ”¢ é™åˆ¶è·å–æœ€æ–°Næ¡è¯„è®º
        - ğŸ” æŒä¹…åŒ–ç™»å½•çŠ¶æ€
        - ğŸ“„ åˆ†é¡µè·å–å…¨éƒ¨è¯„è®º
        """)
    
    # ä¸»å†…å®¹åŒºåŸŸ
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸ“ ä½œå“é“¾æ¥è¾“å…¥")
        
        # é“¾æ¥è¾“å…¥æ–¹å¼é€‰æ‹©
        input_method = st.radio(
            "é€‰æ‹©è¾“å…¥æ–¹å¼:",
            ["å•ä¸ªé“¾æ¥", "æ‰¹é‡é“¾æ¥"],
            horizontal=True
        )
        
        urls = []
        
        if input_method == "å•ä¸ªé“¾æ¥":
            url_input = st.text_input(
                "å°çº¢ä¹¦ä½œå“é“¾æ¥:",
                placeholder="https://www.xiaohongshu.com/explore/...",
                help="è¯·è¾“å…¥å®Œæ•´çš„å°çº¢ä¹¦ä½œå“é“¾æ¥",
                value="https://www.xiaohongshu.com/explore/685613550000000010027087?xsec_token=ABsx19iTZOBngP5o8tS4RRtdE2zXnVe4T1-dVE1Kt2joY=&xsec_source=pc_search&source=web_explore_feed"
            )
            if url_input:
                urls = [url_input]
        else:
            url_input = st.text_area(
                "æ‰¹é‡é“¾æ¥è¾“å…¥ (æ¯è¡Œä¸€ä¸ª):",
                height=150,
                placeholder="https://www.xiaohongshu.com/explore/...\nhttps://www.xiaohongshu.com/explore/...",
                help="æ¯è¡Œè¾“å…¥ä¸€ä¸ªå°çº¢ä¹¦ä½œå“é“¾æ¥"
            )
            if url_input:
                urls = [url.strip() for url in url_input.split('\n') if url.strip()]
        
        # URLéªŒè¯å’Œæ˜¾ç¤º
        if urls:
            st.subheader("ğŸ” é“¾æ¥éªŒè¯")
            valid_urls = []
            for i, url in enumerate(urls):
                col_status, col_url, col_id = st.columns([1, 3, 1])
                
                is_valid = validate_xhs_url(url)
                with col_status:
                    if is_valid:
                        st.success("âœ… æœ‰æ•ˆ")
                        valid_urls.append(url)
                    else:
                        st.error("âŒ æ— æ•ˆ")
                
                with col_url:
                    st.text(url[:80] + "..." if len(url) > 80 else url)
                
                with col_id:
                    if is_valid:
                        note_id = extract_note_id_simple(url)
                        st.code(note_id[:12])
            
            urls = valid_urls
        
        # å¼€å§‹æå–æŒ‰é’®
        st.markdown("---")
        
        # æ£€æŸ¥æ˜¯å¦å¯ä»¥å¼€å§‹
        can_start = (
            len(urls) > 0 and 
            cookie_input.strip() and 
            st.session_state.extraction_status not in ['running']
        )
        
        # çŠ¶æ€æ£€æŸ¥å’Œé”™è¯¯æç¤º
        if not cookie_input.strip():
            st.warning("âš ï¸ è¯·å…ˆè¾“å…¥Cookie!")
        if not urls:
            st.warning("âš ï¸ è¯·å…ˆè¾“å…¥æœ‰æ•ˆçš„ä½œå“é“¾æ¥!")
        
        # å¼€å§‹æŒ‰é’®
        if st.button(
            f"ğŸš€ å¼€å§‹æå–è¯„è®º ({len(urls)} ä¸ªä½œå“)" if urls else "ğŸš€ å¼€å§‹æå–è¯„è®º",
            disabled=not can_start,
            type="primary"
        ):
            # ç«‹å³æ›´æ–°çŠ¶æ€
            st.session_state.extraction_status = 'starting'
            st.session_state.extraction_progress = 0
            st.session_state.current_task = "å‡†å¤‡å¼€å§‹..."
            st.session_state.extraction_logs = []
            st.session_state.results = None
            
            # æ˜¾ç¤ºå¼€å§‹ä¿¡æ¯
            st.info("ğŸš€ å¼€å§‹æå–è¯„è®ºï¼Œè¯·ç¨å€™...")
            
            # ç«‹å³é‡æ–°è¿è¡Œä»¥æ˜¾ç¤ºçŠ¶æ€æ›´æ–°
            st.rerun()
    
    with col2:
        st.header("ğŸ“Š æå–çŠ¶æ€")
        
        # çŠ¶æ€æ˜¾ç¤º
        if st.session_state.extraction_status == 'idle':
            st.info("ğŸ’¤ ç­‰å¾…å¼€å§‹...")
            
        elif st.session_state.extraction_status == 'starting':
            st.warning("ğŸš€ æ­£åœ¨å¯åŠ¨...")
            # åœ¨è¿™é‡Œè¿è¡Œæå–
            if 'urls' in locals() and 'cookie_input' in locals() and urls and cookie_input.strip():
                run_extraction_simple(urls, cookie_input.strip(), work_path, max_comments)
                st.rerun()
            
        elif st.session_state.extraction_status == 'running':
            st.warning("â³ æ­£åœ¨æå–ä¸­...")
            
            # è¿›åº¦æ¡
            if st.session_state.extraction_progress > 0:
                st.progress(st.session_state.extraction_progress / 100)
                st.write(f"è¿›åº¦: {st.session_state.extraction_progress:.1f}%")
            
            # å½“å‰ä»»åŠ¡
            if st.session_state.current_task:
                st.write(f"å½“å‰ä»»åŠ¡: {st.session_state.current_task}")
            
            # è‡ªåŠ¨åˆ·æ–°
            time.sleep(2)
            st.rerun()
            
        elif st.session_state.extraction_status == 'completed':
            st.success("âœ… æå–å®Œæˆ!")
            
        elif st.session_state.extraction_status == 'error':
            st.error("âŒ æå–å¤±è´¥!")
        
        # æ—¥å¿—æ˜¾ç¤º
        if st.session_state.extraction_logs:
            st.subheader("ğŸ“‹ å¤„ç†æ—¥å¿—")
            
            # åˆ›å»ºæ—¥å¿—å®¹å™¨
            with st.container():
                # æ˜¾ç¤ºæœ€æ–°çš„10æ¡æ—¥å¿—
                recent_logs = st.session_state.extraction_logs[-10:]
                
                for log in recent_logs:
                    if log['level'] == 'success':
                        st.success(f"{log['time']} - {log['message']}")
                    elif log['level'] == 'error':
                        st.error(f"{log['time']} - {log['message']}")
                    else:
                        st.info(f"{log['time']} - {log['message']}")
    
    # ç»“æœæ˜¾ç¤º
    if st.session_state.results:
        st.markdown("---")
        st.header("ğŸ“ˆ æå–ç»“æœ")
        
        # ç»“æœç»Ÿè®¡
        total = len(st.session_state.results)
        success_count = len([r for r in st.session_state.results if r['status'] == 'success'])
        failed_count = total - success_count
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æ€»æ•°", total)
        with col2:
            st.metric("æˆåŠŸ", success_count)
        with col3:
            st.metric("å¤±è´¥", failed_count)
        
        # è¯¦ç»†ç»“æœè¡¨æ ¼
        st.subheader("è¯¦ç»†ç»“æœ")
        result_data = []
        for result in st.session_state.results:
            status_emoji = "âœ…" if result['status'] == 'success' else "âŒ"
            result_data.append({
                'çŠ¶æ€': f"{status_emoji} {result['status']}",
                'ä½œå“ID': result['note_id'],
                'é“¾æ¥': result['url'][:50] + "..." if len(result['url']) > 50 else result['url'],
                'æ¶ˆæ¯': result['message']
            })
        
        st.dataframe(result_data, use_container_width=True)
        
        # è¾“å‡ºç›®å½•ä¿¡æ¯
        output_path = Path(work_path)
        if output_path.exists():
            st.subheader("ğŸ“‚ è¾“å‡ºç›®å½•")
            st.code(str(output_path.absolute()))
            
            # åˆ—å‡ºç”Ÿæˆçš„æ–‡ä»¶å¤¹
            if list(output_path.iterdir()):
                st.write("ç”Ÿæˆçš„æ–‡ä»¶å¤¹:")
                for item in output_path.iterdir():
                    if item.is_dir() and not item.name.startswith('.'):
                        st.write(f"ğŸ“ {item.name}")

if __name__ == "__main__":
    main()