#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIæ¨¡å‹ç®¡ç†å™¨
ç»Ÿä¸€ç®¡ç†ä¸åŒAIæœåŠ¡çš„æ¥å£å’Œè°ƒç”¨
"""

import asyncio
import json
import time
from abc import ABC, abstractmethod
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass
from enum import Enum
import hashlib


class ModelType(Enum):
    """AIæ¨¡å‹ç±»å‹"""
    MOCK = "mock"                    # æ¨¡æ‹Ÿæ¨¡å‹
    GPT_88_WEB = "88gpt_web"        # 88gpt.vip ç½‘é¡µç‰ˆ
    GPT_88_API = "88gpt_api"        # 88gpt.vip APIç‰ˆï¼ˆå¦‚æœæœ‰ï¼‰
    OPENAI_API = "openai_api"       # OpenAI å®˜æ–¹API
    CLAUDE_API = "claude_api"       # Claude API
    LOCAL_MODEL = "local_model"     # æœ¬åœ°æ¨¡å‹


class TaskType(Enum):
    """ä»»åŠ¡ç±»å‹"""
    IMAGE_ANALYSIS = "image_analysis"           # å›¾ç‰‡åˆ†æ
    TEXT_GENERATION = "text_generation"         # æ–‡æœ¬ç”Ÿæˆ
    IMAGE_GENERATION = "image_generation"       # å›¾ç‰‡ç”Ÿæˆ
    COMPARISON_CREATION = "comparison_creation" # å¯¹æ¯”å›¾åˆ›å»º


@dataclass
class ModelCapability:
    """æ¨¡å‹èƒ½åŠ›æè¿°"""
    can_analyze_images: bool = False
    can_generate_text: bool = False
    can_generate_images: bool = False
    can_create_comparisons: bool = False
    max_image_size: int = 20971520  # 20MB
    max_tokens: int = 4096
    cost_per_request: float = 0.0
    requests_per_hour: int = 1000
    supports_batch: bool = False


@dataclass
class ModelConfig:
    """æ¨¡å‹é…ç½®"""
    model_type: ModelType
    model_name: str
    api_key: Optional[str] = None
    base_url: Optional[str] = None
    capabilities: Optional[ModelCapability] = None
    priority: int = 1  # ä¼˜å…ˆçº§ï¼Œ1æœ€é«˜
    enabled: bool = True
    timeout: int = 300
    max_retries: int = 3


@dataclass
class TaskRequest:
    """ä»»åŠ¡è¯·æ±‚"""
    task_id: str
    task_type: TaskType
    prompt: str
    image_paths: List[str] = None
    parameters: Dict[str, Any] = None
    priority: int = 1
    timestamp: datetime = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now()
        if self.image_paths is None:
            self.image_paths = []
        if self.parameters is None:
            self.parameters = {}


@dataclass
class TaskResult:
    """ä»»åŠ¡ç»“æœ"""
    task_id: str
    success: bool
    result: Any = None
    error: str = None
    model_used: str = None
    processing_time: float = 0.0
    cost_estimate: float = 0.0
    timestamp: datetime = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now()


class BaseAIModel(ABC):
    """AIæ¨¡å‹åŸºç±»"""
    
    def __init__(self, config: ModelConfig):
        self.config = config
        self.request_count = 0
        self.total_cost = 0.0
        self.last_request_time = None
        self.error_count = 0
        
    @abstractmethod
    async def process_task(self, request: TaskRequest) -> TaskResult:
        """å¤„ç†ä»»åŠ¡"""
        pass
    
    def can_handle_task(self, task_type: TaskType) -> bool:
        """æ£€æŸ¥æ˜¯å¦èƒ½å¤„ç†æŒ‡å®šç±»å‹çš„ä»»åŠ¡"""
        if not self.config.capabilities:
            return False
            
        capability_map = {
            TaskType.IMAGE_ANALYSIS: self.config.capabilities.can_analyze_images,
            TaskType.TEXT_GENERATION: self.config.capabilities.can_generate_text,
            TaskType.IMAGE_GENERATION: self.config.capabilities.can_generate_images,
            TaskType.COMPARISON_CREATION: self.config.capabilities.can_create_comparisons
        }
        
        return capability_map.get(task_type, False)
    
    def update_stats(self, processing_time: float, cost: float, success: bool):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        self.request_count += 1
        self.total_cost += cost
        self.last_request_time = datetime.now()
        if not success:
            self.error_count += 1
    
    def get_health_score(self) -> float:
        """è·å–å¥åº·è¯„åˆ† (0-1)"""
        if self.request_count == 0:
            return 1.0
        
        error_rate = self.error_count / self.request_count
        health_score = max(0.0, 1.0 - error_rate)
        
        # å¦‚æœæœ€è¿‘æ²¡æœ‰è¯·æ±‚ï¼Œç¨å¾®é™ä½è¯„åˆ†
        if self.last_request_time:
            time_since_last = datetime.now() - self.last_request_time
            if time_since_last > timedelta(hours=1):
                health_score *= 0.9
        
        return health_score


class MockAIModel(BaseAIModel):
    """æ¨¡æ‹ŸAIæ¨¡å‹ - ç”¨äºå¼€å‘æµ‹è¯•"""
    
    def __init__(self, config: ModelConfig):
        super().__init__(config)
        self.mock_delay = 2
        
        # è®¾ç½®é»˜è®¤èƒ½åŠ›
        if not config.capabilities:
            config.capabilities = ModelCapability(
                can_analyze_images=True,
                can_generate_text=True,
                can_generate_images=True,
                can_create_comparisons=True,
                cost_per_request=0.05
            )
    
    async def process_task(self, request: TaskRequest) -> TaskResult:
        """å¤„ç†æ¨¡æ‹Ÿä»»åŠ¡"""
        start_time = time.time()
        
        try:
            # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            await asyncio.sleep(self.mock_delay)
            
            if request.task_type == TaskType.IMAGE_ANALYSIS:
                result = self._mock_image_analysis(request)
            elif request.task_type == TaskType.TEXT_GENERATION:
                result = self._mock_text_generation(request)
            elif request.task_type == TaskType.IMAGE_GENERATION:
                result = self._mock_image_generation(request)
            elif request.task_type == TaskType.COMPARISON_CREATION:
                result = self._mock_comparison_creation(request)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {request.task_type}")
            
            processing_time = time.time() - start_time
            cost = self.config.capabilities.cost_per_request
            
            self.update_stats(processing_time, cost, True)
            
            return TaskResult(
                task_id=request.task_id,
                success=True,
                result=result,
                model_used=self.config.model_name,
                processing_time=processing_time,
                cost_estimate=cost
            )
            
        except Exception as e:
            processing_time = time.time() - start_time
            self.update_stats(processing_time, 0, False)
            
            return TaskResult(
                task_id=request.task_id,
                success=False,
                error=str(e),
                model_used=self.config.model_name,
                processing_time=processing_time
            )
    
    def _mock_image_analysis(self, request: TaskRequest) -> Dict:
        """æ¨¡æ‹Ÿå›¾ç‰‡åˆ†æ"""
        return {
            "analysis": f"""
## æˆ¿å±‹åˆ†æç»“æœ (æ¨¡æ‹Ÿ)

åŸºäºç”¨æˆ·æç¤ºï¼š{request.prompt[:100]}...

### ç©ºé—´åŸºæœ¬ä¿¡æ¯
- æˆ¿é—´ç±»å‹ï¼šå®¢å…
- ä¼°ç®—é¢ç§¯ï¼š25å¹³æ–¹ç±³
- é‡‡å…‰æ¡ä»¶ï¼šè‰¯å¥½
- ç°æœ‰é£æ ¼ï¼šç®€çº¦ç°ä»£

### æ”¹é€ å»ºè®®
- ä¼˜åŒ–ç©ºé—´å¸ƒå±€
- å¢åŠ æ”¶çº³åŠŸèƒ½
- è°ƒæ•´è‰²å½©æ­é…
- æå‡æ•´ä½“ç¾è§‚åº¦

### é¢„ç®—ä¼°ç®—
- ç»æµå‹æ”¹é€ ï¼š1-2ä¸‡å…ƒ
- æ ‡å‡†å‹æ”¹é€ ï¼š2-3ä¸‡å…ƒ
- è±ªåå‹æ”¹é€ ï¼š3-5ä¸‡å…ƒ
            """,
            "confidence": 0.85,
            "detected_objects": ["æ²™å‘", "èŒ¶å‡ ", "ç”µè§†", "çª—å¸˜"],
            "room_type": "å®¢å…",
            "estimated_area": 25
        }
    
    def _mock_text_generation(self, request: TaskRequest) -> Dict:
        """æ¨¡æ‹Ÿæ–‡æœ¬ç”Ÿæˆ"""
        return {
            "generated_text": f"""
## ğŸ  ä¸“ä¸šæ”¹é€ å»ºè®®

æ ¹æ®æ‚¨çš„éœ€æ±‚ï¼š{request.prompt[:50]}...

### æ–¹æ¡ˆä¸€ï¼šç°ä»£ç®€çº¦é£æ ¼
- **è®¾è®¡ç†å¿µ**ï¼šç®€æ´ã€å®ç”¨ã€ç°ä»£
- **è‰²å½©æ­é…**ï¼šç™½è‰²ä¸»è°ƒï¼Œæœ¨è‰²ç‚¹ç¼€
- **å®¶å…·å»ºè®®**ï¼šå®œå®¶ç®€çº¦ç³»åˆ—
- **é¢„ç®—èŒƒå›´**ï¼š15000-20000å…ƒ

### æ–¹æ¡ˆäºŒï¼šåŒ—æ¬§è‡ªç„¶é£æ ¼
- **è®¾è®¡ç†å¿µ**ï¼šè‡ªç„¶ã€æ¸©é¦¨ã€èˆ’é€‚
- **è‰²å½©æ­é…**ï¼šç±³ç™½è‰²ï¼ŒåŸæœ¨è‰²
- **å®¶å…·å»ºè®®**ï¼šå®æœ¨å®¶å…·ï¼Œç»¿æ¤è£…é¥°
- **é¢„ç®—èŒƒå›´**ï¼š18000-25000å…ƒ

### å®æ–½å»ºè®®
1. ä¼˜å…ˆå¤„ç†åŠŸèƒ½æ€§é—®é¢˜
2. å…¶æ¬¡è€ƒè™‘ç¾è§‚æ€§æå‡
3. æœ€åè¿›è¡Œç»†èŠ‚ä¼˜åŒ–

å¸Œæœ›è¿™äº›å»ºè®®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼å¦‚éœ€æ›´è¯¦ç»†çš„æ–¹æ¡ˆï¼Œæ¬¢è¿è¿›ä¸€æ­¥å’¨è¯¢ï½
            """,
            "word_count": 200,
            "sentiment": "ç§¯æ",
            "style": "ä¸“ä¸šå‹å¥½"
        }
    
    def _mock_image_generation(self, request: TaskRequest) -> Dict:
        """æ¨¡æ‹Ÿå›¾ç‰‡ç”Ÿæˆ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        mock_path = f"Comments_Dynamic/generated_images/mock_{timestamp}.png"
        
        return {
            "image_url": f"https://mock-image-service.com/generated_{timestamp}.png",
            "local_path": mock_path,
            "style": request.parameters.get("style", "ç°ä»£ç®€çº¦"),
            "resolution": "1024x1024",
            "quality": "high"
        }
    
    def _mock_comparison_creation(self, request: TaskRequest) -> Dict:
        """æ¨¡æ‹Ÿå¯¹æ¯”å›¾åˆ›å»º"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        comparison_path = f"Comments_Dynamic/generated_images/comparison_{timestamp}.png"
        
        return {
            "comparison_url": f"https://mock-comparison.com/comparison_{timestamp}.png",
            "local_path": comparison_path,
            "layout": "side_by_side",
            "highlights": ["ç©ºé—´å¸ƒå±€å˜åŒ–", "è‰²å½©æ­é…ä¼˜åŒ–", "å®¶å…·æ›´æ–°"]
        }


class WebAutomationModel(BaseAIModel):
    """ç½‘é¡µè‡ªåŠ¨åŒ–æ¨¡å‹åŸºç±» - ç”¨äº88gpt.vipç­‰ç½‘é¡µç‰ˆAIæœåŠ¡"""
    
    def __init__(self, config: ModelConfig):
        super().__init__(config)
        self.browser = None
        self.page = None
        self.is_logged_in = False
        self.daily_usage_count = 0
        self.daily_limit = 150  # 88gpt.vipçš„8å°æ—¶150æ¬¡é™åˆ¶
        self.last_reset_time = datetime.now().date()
    
    async def init_browser(self):
        """åˆå§‹åŒ–æµè§ˆå™¨"""
        if self.browser is None:
            from playwright.async_api import async_playwright
            self.playwright = await async_playwright().start()
            self.browser = await self.playwright.chromium.launch(
                headless=True,  # å¯ä»¥æ”¹ä¸ºFalseæ¥è°ƒè¯•
                args=['--no-sandbox', '--disable-dev-shm-usage']
            )
            self.page = await self.browser.new_page()
            
            # è®¾ç½®ç”¨æˆ·ä»£ç†
            await self.page.set_user_agent(
                "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
            )
    
    async def close_browser(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.browser:
            await self.browser.close()
            await self.playwright.stop()
            self.browser = None
            self.page = None
    
    def check_daily_limit(self) -> bool:
        """æ£€æŸ¥æ¯æ—¥ä½¿ç”¨é™åˆ¶"""
        today = datetime.now().date()
        if today > self.last_reset_time:
            self.daily_usage_count = 0
            self.last_reset_time = today
        
        return self.daily_usage_count < self.daily_limit
    
    def update_daily_usage(self):
        """æ›´æ–°æ¯æ—¥ä½¿ç”¨é‡"""
        self.daily_usage_count += 1


class GPT88WebModel(WebAutomationModel):
    """88gpt.vip ç½‘é¡µç‰ˆæ¨¡å‹"""
    
    def __init__(self, config: ModelConfig):
        super().__init__(config)
        
        # è®¾ç½®èƒ½åŠ›
        if not config.capabilities:
            config.capabilities = ModelCapability(
                can_analyze_images=True,
                can_generate_text=True,
                can_generate_images=True,
                can_create_comparisons=True,
                cost_per_request=0.0,  # 88gptæŒ‰æ¬¡æ•°è®¡è´¹ï¼Œä¸æ˜¯token
                requests_per_hour=18   # 150æ¬¡/8å°æ—¶ â‰ˆ 18æ¬¡/å°æ—¶
            )
    
    async def process_task(self, request: TaskRequest) -> TaskResult:
        """å¤„ç†88gpt.vipä»»åŠ¡"""
        start_time = time.time()
        
        try:
            # æ£€æŸ¥ä½¿ç”¨é™åˆ¶
            if not self.check_daily_limit():
                raise Exception("å·²è¾¾åˆ°88gpt.vipæ¯æ—¥ä½¿ç”¨é™åˆ¶")
            
            # åˆå§‹åŒ–æµè§ˆå™¨
            await self.init_browser()
            
            # å¯¼èˆªåˆ°88gpt.vip
            await self._navigate_to_88gpt()
            
            # æ ¹æ®ä»»åŠ¡ç±»å‹å¤„ç†
            if request.task_type == TaskType.IMAGE_ANALYSIS:
                result = await self._process_image_analysis(request)
            elif request.task_type == TaskType.TEXT_GENERATION:
                result = await self._process_text_generation(request)
            elif request.task_type == TaskType.IMAGE_GENERATION:
                result = await self._process_image_generation(request)
            else:
                raise ValueError(f"88gpt.vipæš‚ä¸æ”¯æŒä»»åŠ¡ç±»å‹: {request.task_type}")
            
            # æ›´æ–°ä½¿ç”¨ç»Ÿè®¡
            self.update_daily_usage()
            processing_time = time.time() - start_time
            self.update_stats(processing_time, 0, True)
            
            return TaskResult(
                task_id=request.task_id,
                success=True,
                result=result,
                model_used=self.config.model_name,
                processing_time=processing_time,
                cost_estimate=0
            )
            
        except Exception as e:
            processing_time = time.time() - start_time
            self.update_stats(processing_time, 0, False)
            
            return TaskResult(
                task_id=request.task_id,
                success=False,
                error=str(e),
                model_used=self.config.model_name,
                processing_time=processing_time
            )
        finally:
            # å…³é—­æµè§ˆå™¨ï¼ˆå¯é€‰ï¼Œä¹Ÿå¯ä»¥ä¿æŒè¿æ¥ï¼‰
            # await self.close_browser()
            pass
    
    async def _navigate_to_88gpt(self):
        """å¯¼èˆªåˆ°88gpt.vip"""
        await self.page.goto("https://www.88gpt.vip/")
        await self.page.wait_for_load_state("networkidle")
        
        # TODO: å¦‚æœéœ€è¦ç™»å½•ï¼Œåœ¨è¿™é‡Œå¤„ç†ç™»å½•é€»è¾‘
        # await self._login_if_needed()
    
    async def _process_image_analysis(self, request: TaskRequest) -> Dict:
        """å¤„ç†å›¾ç‰‡åˆ†æä»»åŠ¡"""
        # TODO: å®ç°88gpt.vipçš„å›¾ç‰‡åˆ†æ
        # 1. ä¸Šä¼ å›¾ç‰‡
        # 2. å‘é€åˆ†ææç¤ºè¯
        # 3. ç­‰å¾…å“åº”
        # 4. è§£æç»“æœ
        
        # å ä½ç¬¦å®ç°
        await asyncio.sleep(5)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        
        return {
            "analysis": f"88gpt.vipåˆ†æç»“æœï¼š{request.prompt}",
            "source": "88gpt.vip",
            "model": "gpt-4o"
        }
    
    async def _process_text_generation(self, request: TaskRequest) -> Dict:
        """å¤„ç†æ–‡æœ¬ç”Ÿæˆä»»åŠ¡"""
        # TODO: å®ç°88gpt.vipçš„æ–‡æœ¬ç”Ÿæˆ
        # 1. è¾“å…¥æç¤ºè¯
        # 2. ç‚¹å‡»å‘é€
        # 3. ç­‰å¾…å“åº”
        # 4. æå–ç”Ÿæˆçš„æ–‡æœ¬
        
        # å ä½ç¬¦å®ç°
        await asyncio.sleep(3)
        
        return {
            "generated_text": f"88gpt.vipç”Ÿæˆï¼š{request.prompt[:50]}...",
            "source": "88gpt.vip",
            "model": "gpt-4o"
        }
    
    async def _process_image_generation(self, request: TaskRequest) -> Dict:
        """å¤„ç†å›¾ç‰‡ç”Ÿæˆä»»åŠ¡"""
        # TODO: å®ç°88gpt.vipçš„å›¾ç‰‡ç”Ÿæˆ
        # 1. åˆ‡æ¢åˆ°å›¾ç‰‡ç”Ÿæˆæ¨¡å¼
        # 2. è¾“å…¥å›¾ç‰‡æè¿°
        # 3. ç­‰å¾…å›¾ç‰‡ç”Ÿæˆ
        # 4. ä¸‹è½½å›¾ç‰‡
        
        # å ä½ç¬¦å®ç°
        await asyncio.sleep(10)
        
        return {
            "image_url": "https://88gpt.vip/generated_image.png",
            "local_path": "Comments_Dynamic/generated_images/88gpt_image.png",
            "source": "88gpt.vip",
            "model": "dall-e-3"
        }


class AIModelManager:
    """AIæ¨¡å‹ç®¡ç†å™¨"""
    
    def __init__(self, config_path: str = "config/ai_models.json"):
        self.config_path = Path(config_path)
        self.models: Dict[str, BaseAIModel] = {}
        self.task_queue = asyncio.Queue()
        self.processing_tasks = {}
        self.history_path = Path("Comments_Dynamic/ai_model_history")
        self.history_path.mkdir(parents=True, exist_ok=True)
        
        # åŠ è½½æ¨¡å‹é…ç½®
        self.load_model_configs()
    
    def load_model_configs(self):
        """åŠ è½½æ¨¡å‹é…ç½®"""
        # é»˜è®¤é…ç½®
        default_configs = [
            ModelConfig(
                model_type=ModelType.MOCK,
                model_name="mock_gpt4o",
                capabilities=ModelCapability(
                    can_analyze_images=True,
                    can_generate_text=True,
                    can_generate_images=True,
                    can_create_comparisons=True,
                    cost_per_request=0.05
                ),
                priority=2,
                enabled=True
            ),
            ModelConfig(
                model_type=ModelType.GPT_88_WEB,
                model_name="88gpt_web_gpt4o",
                base_url="https://www.88gpt.vip/",
                capabilities=ModelCapability(
                    can_analyze_images=True,
                    can_generate_text=True,
                    can_generate_images=True,
                    can_create_comparisons=True,
                    cost_per_request=0.0,
                    requests_per_hour=18
                ),
                priority=1,
                enabled=False  # é»˜è®¤ç¦ç”¨ï¼Œéœ€è¦æ‰‹åŠ¨å¯ç”¨
            )
        ]
        
        # å¦‚æœé…ç½®æ–‡ä»¶å­˜åœ¨ï¼ŒåŠ è½½é…ç½®
        if self.config_path.exists():
            try:
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    config_data = json.load(f)
                # TODO: è§£æé…ç½®æ–‡ä»¶å¹¶æ›´æ–°default_configs
            except Exception as e:
                print(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        for config in default_configs:
            if config.enabled:
                self.register_model(config)
    
    def register_model(self, config: ModelConfig):
        """æ³¨å†Œæ¨¡å‹"""
        if config.model_type == ModelType.MOCK:
            model = MockAIModel(config)
        elif config.model_type == ModelType.GPT_88_WEB:
            model = GPT88WebModel(config)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {config.model_type}")
        
        self.models[config.model_name] = model
        print(f"âœ… æ³¨å†Œæ¨¡å‹: {config.model_name}")
    
    def get_available_models(self, task_type: TaskType) -> List[BaseAIModel]:
        """è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
        available = []
        for model in self.models.values():
            if (model.config.enabled and 
                model.can_handle_task(task_type) and 
                model.get_health_score() > 0.5):
                available.append(model)
        
        # æŒ‰ä¼˜å…ˆçº§å’Œå¥åº·è¯„åˆ†æ’åº
        available.sort(key=lambda m: (m.config.priority, -m.get_health_score()))
        return available
    
    def select_best_model(self, task_type: TaskType) -> Optional[BaseAIModel]:
        """é€‰æ‹©æœ€ä½³æ¨¡å‹"""
        available_models = self.get_available_models(task_type)
        return available_models[0] if available_models else None
    
    async def process_task(self, request: TaskRequest, 
                          preferred_model: str = None) -> TaskResult:
        """å¤„ç†ä»»åŠ¡"""
        
        # å¦‚æœæŒ‡å®šäº†é¦–é€‰æ¨¡å‹ï¼Œä¼˜å…ˆä½¿ç”¨
        if preferred_model and preferred_model in self.models:
            model = self.models[preferred_model]
            if model.can_handle_task(request.task_type):
                return await model.process_task(request)
        
        # è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ¨¡å‹
        model = self.select_best_model(request.task_type)
        if not model:
            return TaskResult(
                task_id=request.task_id,
                success=False,
                error=f"æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹å¤„ç†ä»»åŠ¡ç±»å‹: {request.task_type}"
            )
        
        # å¤„ç†ä»»åŠ¡
        result = await model.process_task(request)
        
        # ä¿å­˜å†å²è®°å½•
        await self.save_task_history(request, result)
        
        return result
    
    async def save_task_history(self, request: TaskRequest, result: TaskResult):
        """ä¿å­˜ä»»åŠ¡å†å²"""
        history_record = {
            "request": {
                "task_id": request.task_id,
                "task_type": request.task_type.value,
                "prompt": request.prompt[:200] + "..." if len(request.prompt) > 200 else request.prompt,
                "timestamp": request.timestamp.isoformat()
            },
            "result": {
                "success": result.success,
                "model_used": result.model_used,
                "processing_time": result.processing_time,
                "cost_estimate": result.cost_estimate,
                "error": result.error,
                "timestamp": result.timestamp.isoformat()
            }
        }
        
        history_file = self.history_path / f"task_{request.task_id}.json"
        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump(history_record, f, ensure_ascii=False, indent=2)
    
    def get_model_statistics(self) -> Dict:
        """è·å–æ¨¡å‹ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        for name, model in self.models.items():
            stats[name] = {
                "model_type": model.config.model_type.value,
                "enabled": model.config.enabled,
                "request_count": model.request_count,
                "total_cost": model.total_cost,
                "error_count": model.error_count,
                "health_score": model.get_health_score(),
                "last_request": model.last_request_time.isoformat() if model.last_request_time else None
            }
        return stats
    
    async def enable_model(self, model_name: str):
        """å¯ç”¨æ¨¡å‹"""
        if model_name in self.models:
            self.models[model_name].config.enabled = True
            print(f"âœ… å¯ç”¨æ¨¡å‹: {model_name}")
        else:
            print(f"âŒ æ¨¡å‹ä¸å­˜åœ¨: {model_name}")
    
    async def disable_model(self, model_name: str):
        """ç¦ç”¨æ¨¡å‹"""
        if model_name in self.models:
            self.models[model_name].config.enabled = False
            print(f"â¸ï¸ ç¦ç”¨æ¨¡å‹: {model_name}")
        else:
            print(f"âŒ æ¨¡å‹ä¸å­˜åœ¨: {model_name}")


# æµ‹è¯•å‡½æ•°
async def test_ai_model_manager():
    """æµ‹è¯•AIæ¨¡å‹ç®¡ç†å™¨"""
    
    manager = AIModelManager()
    
    print("ğŸ§ª å¼€å§‹æµ‹è¯•AIæ¨¡å‹ç®¡ç†å™¨")
    print("="*50)
    
    # æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
    print("ğŸ“‹ å¯ç”¨æ¨¡å‹:")
    stats = manager.get_model_statistics()
    for name, stat in stats.items():
        print(f"   {name}: {stat['model_type']} - {'å¯ç”¨' if stat['enabled'] else 'ç¦ç”¨'}")
    
    # æµ‹è¯•ä¸åŒç±»å‹çš„ä»»åŠ¡
    test_tasks = [
        TaskRequest(
            task_id="test_1",
            task_type=TaskType.IMAGE_ANALYSIS,
            prompt="è¯·åˆ†æè¿™ä¸ªå®¢å…çš„æ”¹é€ æ½œåŠ›",
            image_paths=["test_room.jpg"]
        ),
        TaskRequest(
            task_id="test_2",
            task_type=TaskType.TEXT_GENERATION,
            prompt="ä¸ºç”¨æˆ·ç”Ÿæˆå®¢å…æ”¹é€ å»ºè®®"
        ),
        TaskRequest(
            task_id="test_3",
            task_type=TaskType.IMAGE_GENERATION,
            prompt="ç”Ÿæˆç°ä»£ç®€çº¦é£æ ¼çš„å®¢å…æ•ˆæœå›¾",
            parameters={"style": "ç°ä»£ç®€çº¦"}
        )
    ]
    
    # å¤„ç†æµ‹è¯•ä»»åŠ¡
    for task in test_tasks:
        print(f"\nğŸ”„ å¤„ç†ä»»åŠ¡: {task.task_type.value}")
        result = await manager.process_task(task)
        
        if result.success:
            print(f"   âœ… æˆåŠŸ - æ¨¡å‹: {result.model_used}")
            print(f"   â±ï¸ è€—æ—¶: {result.processing_time:.2f}ç§’")
            print(f"   ğŸ’° æˆæœ¬: ${result.cost_estimate:.4f}")
        else:
            print(f"   âŒ å¤±è´¥: {result.error}")
    
    # æ˜¾ç¤ºæ›´æ–°åçš„ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“ˆ æ¨¡å‹ç»Ÿè®¡:")
    updated_stats = manager.get_model_statistics()
    for name, stat in updated_stats.items():
        if stat['request_count'] > 0:
            print(f"   {name}:")
            print(f"      è¯·æ±‚æ¬¡æ•°: {stat['request_count']}")
            print(f"      å¥åº·è¯„åˆ†: {stat['health_score']:.2f}")
            print(f"      æ€»æˆæœ¬: ${stat['total_cost']:.4f}")


if __name__ == "__main__":
    asyncio.run(test_ai_model_manager())