#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœ¬åœ°è¯„è®ºæ•°æ®åŠ è½½å™¨
ä»Comments_Dynamicç›®å½•ä¸­åŠ è½½å†å²è¯„è®ºæ•°æ®
"""

import json
import os
import time
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import re


class LocalCommentLoader:
    """æœ¬åœ°è¯„è®ºæ•°æ®åŠ è½½å™¨"""
    
    def __init__(self, base_path: str = "Comments_Dynamic"):
        """åˆå§‹åŒ–åŠ è½½å™¨
        
        Args:
            base_path: Comments_Dynamicç›®å½•è·¯å¾„
        """
        self.base_path = Path(base_path)
        self._works_cache = None
        self._last_scan_time = None
    
    def scan_available_works(self, force_refresh: bool = False) -> List[Dict]:
        """æ‰«æå¯ç”¨çš„ä½œå“ç›®å½•
        
        Args:
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ç¼“å­˜
            
        Returns:
            ä½œå“ä¿¡æ¯åˆ—è¡¨
        """
        # æ£€æŸ¥ç¼“å­˜
        current_time = time.time()
        if (not force_refresh and 
            self._works_cache and 
            self._last_scan_time and 
            current_time - self._last_scan_time < 60):  # 1åˆ†é’Ÿç¼“å­˜
            return self._works_cache
        
        works = []
        
        if not self.base_path.exists():
            return works
        
        # æ‰«ææ‰€æœ‰å­ç›®å½•
        for work_dir in self.base_path.iterdir():
            if not work_dir.is_dir():
                continue
            
            # è·³è¿‡ç‰¹æ®Šç›®å½•
            skip_dirs = ['browser_profile', 'debug', 'test_work', 'all_comment_images']
            if work_dir.name in skip_dirs:
                continue
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ä½œå“ä¿¡æ¯æ–‡ä»¶
            work_info_file = work_dir / "ä½œå“ä¿¡æ¯.json"
            if not work_info_file.exists():
                continue
            
            try:
                # è¯»å–ä½œå“ä¿¡æ¯
                with open(work_info_file, 'r', encoding='utf-8') as f:
                    work_info = json.load(f)
                
                # ç»Ÿè®¡è¯„è®ºæ•°é‡
                comment_count = self._count_comments_in_work(work_dir)
                
                # è·å–æœ€æ–°è¯„è®ºæ—¶é—´
                latest_comment_time = self._get_latest_comment_time(work_dir)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡
                has_images = self._check_work_has_images(work_dir)
                
                work_data = {
                    'work_title': work_info.get('ä½œå“æ ‡é¢˜', work_dir.name),
                    'work_id': work_info.get('ä½œå“ID', ''),
                    'work_link': work_info.get('ä½œå“é“¾æ¥', ''),
                    'work_description': work_info.get('ä½œå“æè¿°', ''),
                    'work_dir': str(work_dir),
                    'comment_count': comment_count,
                    'latest_comment_time': latest_comment_time,
                    'has_images': has_images,
                    'scan_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                
                works.append(work_data)
                
            except Exception as e:
                print(f"è¯»å–ä½œå“ä¿¡æ¯å¤±è´¥ {work_dir.name}: {e}")
                continue
        
        # æŒ‰æœ€æ–°è¯„è®ºæ—¶é—´æ’åº
        works.sort(key=lambda x: x['latest_comment_time'] or '', reverse=True)
        
        # æ›´æ–°ç¼“å­˜
        self._works_cache = works
        self._last_scan_time = current_time
        
        return works
    
    def load_comments_from_work(self, work_dir: str) -> List[Dict]:
        """ä»æŒ‡å®šä½œå“ç›®å½•åŠ è½½è¯„è®ºæ•°æ®
        
        Args:
            work_dir: ä½œå“ç›®å½•è·¯å¾„
            
        Returns:
            è¯„è®ºæ•°æ®åˆ—è¡¨
        """
        work_path = Path(work_dir)
        if not work_path.exists():
            return []
        
        comments = []
        
        # éå†æ‰€æœ‰ç”¨æˆ·ç›®å½•
        for user_dir in work_path.iterdir():
            if not user_dir.is_dir():
                continue
            
            # è·³è¿‡ç‰¹æ®Šæ–‡ä»¶
            if user_dir.name in ['ä½œå“ä¿¡æ¯.json', 'æå–æŠ¥å‘Š.txt']:
                continue
            
            # è¯»å–è¯„è®ºæ•°æ®
            comment_data = self._load_single_comment(user_dir)
            if comment_data:
                comments.append(comment_data)
        
        # æŒ‰æ—¶é—´æ’åºï¼ˆæœ€æ–°åœ¨å‰ï¼‰
        comments.sort(key=lambda x: x.get('create_time', 0), reverse=True)
        
        return comments
    
    def _load_single_comment(self, user_dir: Path) -> Optional[Dict]:
        """åŠ è½½å•ä¸ªè¯„è®ºæ•°æ®
        
        Args:
            user_dir: ç”¨æˆ·è¯„è®ºç›®å½•
            
        Returns:
            è¯„è®ºæ•°æ®å­—å…¸
        """
        try:
            # è¯»å–åŸå§‹æ•°æ®
            raw_data_file = user_dir / "åŸå§‹æ•°æ®.json"
            if not raw_data_file.exists():
                return None
            
            with open(raw_data_file, 'r', encoding='utf-8') as f:
                raw_data = json.load(f)
            
            # æå–åŸºæœ¬ä¿¡æ¯
            user_info = raw_data.get('user_info', {})
            nickname = user_info.get('nickname', user_dir.name)
            content = raw_data.get('content', '')
            create_time = raw_data.get('create_time', 0)
            
            # è½¬æ¢æ—¶é—´æ ¼å¼
            if create_time:
                try:
                    # è½¬æ¢æ¯«ç§’æ—¶é—´æˆ³ä¸ºå¯è¯»æ ¼å¼
                    time_str = datetime.fromtimestamp(create_time / 1000).strftime('%Y-%m-%d %H:%M:%S')
                except:
                    time_str = str(create_time)
            else:
                time_str = 'æœªçŸ¥æ—¶é—´'
            
            # æå–å›¾ç‰‡URL
            image_urls = []
            images_data = raw_data.get('images', [])
            for img_data in images_data:
                if isinstance(img_data, dict):
                    # ä¼˜å…ˆä½¿ç”¨urlDefaultï¼Œå…¶æ¬¡ä½¿ç”¨urlPre
                    url = img_data.get('urlDefault') or img_data.get('urlPre')
                    if url:
                        image_urls.append(url)
                elif isinstance(img_data, str):
                    image_urls.append(img_data)
            
            # æŸ¥æ‰¾å·²ä¸‹è½½çš„å›¾ç‰‡
            downloaded_images = []
            for file_path in user_dir.iterdir():
                if file_path.is_file() and file_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.gif']:
                    downloaded_images.append(str(file_path))
            
            # æ„é€ è¯„è®ºæ•°æ®ï¼ˆä¸ç°æœ‰æ ¼å¼å…¼å®¹ï¼‰
            comment_data = {
                'nickname': nickname,
                'time': time_str,
                'content': content,
                'images': image_urls,
                'downloaded_images': downloaded_images,
                'comment_dir': str(user_dir),
                'timestamp': datetime.now().strftime("%H:%M:%S"),
                'create_time': create_time,
                'user_info': user_info,
                'raw_data': raw_data
            }
            
            return comment_data
            
        except Exception as e:
            print(f"åŠ è½½è¯„è®ºæ•°æ®å¤±è´¥ {user_dir.name}: {e}")
            return None
    
    def _count_comments_in_work(self, work_dir: Path) -> int:
        """ç»Ÿè®¡ä½œå“ä¸­çš„è¯„è®ºæ•°é‡"""
        count = 0
        for user_dir in work_dir.iterdir():
            if user_dir.is_dir() and (user_dir / "åŸå§‹æ•°æ®.json").exists():
                count += 1
        return count
    
    def _get_latest_comment_time(self, work_dir: Path) -> Optional[str]:
        """è·å–ä½œå“ä¸­æœ€æ–°çš„è¯„è®ºæ—¶é—´"""
        latest_time = None
        latest_timestamp = 0
        
        for user_dir in work_dir.iterdir():
            if not user_dir.is_dir():
                continue
            
            raw_data_file = user_dir / "åŸå§‹æ•°æ®.json"
            if not raw_data_file.exists():
                continue
            
            try:
                with open(raw_data_file, 'r', encoding='utf-8') as f:
                    raw_data = json.load(f)
                
                create_time = raw_data.get('create_time', 0)
                if create_time > latest_timestamp:
                    latest_timestamp = create_time
                    try:
                        latest_time = datetime.fromtimestamp(create_time / 1000).strftime('%Y-%m-%d %H:%M:%S')
                    except:
                        latest_time = str(create_time)
                        
            except Exception:
                continue
        
        return latest_time
    
    def _check_work_has_images(self, work_dir: Path) -> bool:
        """æ£€æŸ¥ä½œå“æ˜¯å¦åŒ…å«å›¾ç‰‡"""
        for user_dir in work_dir.iterdir():
            if not user_dir.is_dir():
                continue
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡æ–‡ä»¶
            for file_path in user_dir.iterdir():
                if file_path.is_file() and file_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.gif']:
                    return True
        
        return False
    
    def get_work_statistics(self, work_dir: str) -> Dict:
        """è·å–ä½œå“ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            work_dir: ä½œå“ç›®å½•è·¯å¾„
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        comments = self.load_comments_from_work(work_dir)
        
        total_comments = len(comments)
        total_images = sum(len(comment.get('images', [])) for comment in comments)
        comments_with_images = sum(1 for comment in comments if comment.get('downloaded_images'))
        total_downloaded_images = sum(len(comment.get('downloaded_images', [])) for comment in comments)
        
        return {
            'total_comments': total_comments,
            'total_images': total_images,
            'comments_with_images': comments_with_images,
            'total_downloaded_images': total_downloaded_images,
            'comments_without_images': total_comments - comments_with_images
        }
    
    def search_comments(self, work_dir: str, search_term: str = "", 
                       show_images_only: bool = False) -> List[Dict]:
        """æœç´¢å’Œç­›é€‰è¯„è®º
        
        Args:
            work_dir: ä½œå“ç›®å½•è·¯å¾„
            search_term: æœç´¢å…³é”®è¯
            show_images_only: æ˜¯å¦åªæ˜¾ç¤ºæœ‰å›¾è¯„è®º
            
        Returns:
            ç­›é€‰åçš„è¯„è®ºåˆ—è¡¨
        """
        comments = self.load_comments_from_work(work_dir)
        
        # å…³é”®è¯æœç´¢
        if search_term:
            search_term = search_term.lower()
            comments = [
                comment for comment in comments 
                if (search_term in comment.get('content', '').lower() or 
                    search_term in comment.get('nickname', '').lower())
            ]
        
        # ç­›é€‰æœ‰å›¾è¯„è®º
        if show_images_only:
            comments = [
                comment for comment in comments 
                if comment.get('downloaded_images') or comment.get('images')
            ]
        
        return comments
    
    def export_work_summary(self, work_dir: str) -> str:
        """å¯¼å‡ºä½œå“æ‘˜è¦ä¿¡æ¯
        
        Args:
            work_dir: ä½œå“ç›®å½•è·¯å¾„
            
        Returns:
            æ‘˜è¦æ–‡æœ¬
        """
        work_path = Path(work_dir)
        
        # è¯»å–ä½œå“ä¿¡æ¯
        work_info_file = work_path / "ä½œå“ä¿¡æ¯.json"
        try:
            with open(work_info_file, 'r', encoding='utf-8') as f:
                work_info = json.load(f)
        except:
            work_info = {'ä½œå“æ ‡é¢˜': work_path.name}
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = self.get_work_statistics(work_dir)
        comments = self.load_comments_from_work(work_dir)
        
        # ç”Ÿæˆæ‘˜è¦
        summary = f"""
# {work_info.get('ä½œå“æ ‡é¢˜', 'æœªçŸ¥ä½œå“')} - è¯„è®ºæ‘˜è¦

## åŸºæœ¬ä¿¡æ¯
- ä½œå“ID: {work_info.get('ä½œå“ID', 'æœªçŸ¥')}
- æå–æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- ä½œå“é“¾æ¥: {work_info.get('ä½œå“é“¾æ¥', 'æœªçŸ¥')}

## ç»Ÿè®¡ä¿¡æ¯
- æ€»è¯„è®ºæ•°: {stats['total_comments']} æ¡
- æœ‰å›¾è¯„è®º: {stats['comments_with_images']} æ¡
- çº¯æ–‡æœ¬è¯„è®º: {stats['comments_without_images']} æ¡
- æ€»å›¾ç‰‡æ•°: {stats['total_images']} å¼ 
- å·²ä¸‹è½½å›¾ç‰‡: {stats['total_downloaded_images']} å¼ 

## æœ€æ–°è¯„è®ºé¢„è§ˆ
"""
        
        # æ·»åŠ æœ€æ–°3æ¡è¯„è®º
        for i, comment in enumerate(comments[:3]):
            summary += f"\n### {i+1}. {comment['nickname']} ({comment['time']})\n"
            summary += f"{comment['content']}\n"
            if comment.get('images'):
                summary += f"ğŸ“¸ åŒ…å« {len(comment['images'])} å¼ å›¾ç‰‡\n"
        
        if len(comments) > 3:
            summary += f"\n... è¿˜æœ‰ {len(comments) - 3} æ¡è¯„è®º\n"
        
        return summary